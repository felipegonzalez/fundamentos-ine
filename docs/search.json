[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fundamentos de estadística",
    "section": "",
    "text": "En este curso repasaremos:\n\nBásicos de análisis de datos\nInferencia: pruebas de hipótesis\nInferencia: técnicas de remuestreo\nInferencia bayesiana"
  },
  {
    "objectID": "index.html#código-y-ligas",
    "href": "index.html#código-y-ligas",
    "title": "Fundamentos de estadística",
    "section": "Código y ligas",
    "text": "Código y ligas\n\nRepositorio: Github\nEstas notas: https://felipegonzalez.github.io/fundamentos-ine/inferencia.html"
  },
  {
    "objectID": "numericos.html",
    "href": "numericos.html",
    "title": "1  Datos numéricos",
    "section": "",
    "text": "En esta sección mostraremos cómo hacer distintos tipos de resúmenes para mediciones numéricas. Igual que en la sección anterior, consideraremos también el uso de estas descripciones para comparar distintos grupos (o bonches de datos, como les llamaba Tukey), aplicando repetidamente los mismos resúmenes a lo largo de esos distintos grupos."
  },
  {
    "objectID": "numericos.html#cuantiles-o-percentiles-de-una-variable",
    "href": "numericos.html#cuantiles-o-percentiles-de-una-variable",
    "title": "1  Datos numéricos",
    "section": "1.1 Cuantiles o percentiles de una variable",
    "text": "1.1 Cuantiles o percentiles de una variable\nEmpezamos explicando algunas ideas que no serán útiles más adelante.\nPor ejemplo, los siguientes datos fueron registrados en un restaurante durante cuatro días consecutivos:\n\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(kableExtra)\n# usamos los datos tips del paquete reshape2\npropinas <- read_csv(\"./datos/propinas.csv\")\n\nY vemos una muestra\n\nslice_sample(propinas, n = 10) \n\n# A tibble: 10 × 6\n   cuenta_total propina fumador dia   momento num_personas\n          <dbl>   <dbl> <chr>   <chr> <chr>          <dbl>\n 1         15.5    2.02 Si      Jue   Comida             2\n 2         13.3    2.5  Si      Sab   Cena               2\n 3         16.9    3.07 No      Sab   Cena               3\n 4         25.3    4.71 No      Dom   Cena               4\n 5         13.4    1.68 No      Jue   Comida             2\n 6         35.8    4.67 No      Sab   Cena               3\n 7         23.1    4    Si      Dom   Cena               3\n 8         17.3    2.71 No      Jue   Comida             2\n 9         17.8    1.75 No      Sab   Cena               2\n10         12.7    2.01 Si      Jue   Comida             2\n\n\nAquí la unidad de observación es una cuenta particular. Tenemos tres mediciones numéricas de cada cuenta: cúanto fue la cuenta total, la propina, y el número de personas asociadas a la cuenta. Los datos están separados según se fumó o no en la mesa, y temporalmente en dos partes: el día (Jueves, Viernes, Sábado o Domingo), cada uno separado por Cena y Comida.\nEl primer tipo de comparaciones que nos interesa hacer es para una medición numérica es: ¿Varían mucho o poco los datos? ¿Cuáles son valores típicos o centrales? ¿Existen valores muy extremos alejados de valores típicos?\nSupongamos entonces que consideramos simplemente la variable de cuenta_total. Podemos comenzar por ordenar los datos, y ver cuáles datos están en los extremos y cuáles están en los lugares centrales:\n\npropinas <- propinas |> \n  mutate(orden_cuenta = rank(cuenta_total, ties.method = \"first\"), \n         f = (orden_cuenta - 0.5) / n()) \ncuenta <- propinas |>  \n  select(orden_cuenta, f, cuenta_total) |>  \n  arrange(f)\nbind_rows(head(cuenta), tail(cuenta)) |>  kable() |> \n  kable_paper()\n\n\n\n \n  \n    orden_cuenta \n    f \n    cuenta_total \n  \n \n\n  \n    1 \n    0.0020492 \n    3.07 \n  \n  \n    2 \n    0.0061475 \n    5.75 \n  \n  \n    3 \n    0.0102459 \n    7.25 \n  \n  \n    4 \n    0.0143443 \n    7.25 \n  \n  \n    5 \n    0.0184426 \n    7.51 \n  \n  \n    6 \n    0.0225410 \n    7.56 \n  \n  \n    239 \n    0.9774590 \n    44.30 \n  \n  \n    240 \n    0.9815574 \n    45.35 \n  \n  \n    241 \n    0.9856557 \n    48.17 \n  \n  \n    242 \n    0.9897541 \n    48.27 \n  \n  \n    243 \n    0.9938525 \n    48.33 \n  \n  \n    244 \n    0.9979508 \n    50.81 \n  \n\n\n\n\n\ny graficamos los datos en orden, interpolando valores consecutivos.\n\n\n\n\n\nA esta función le llamamos la función de cuantiles para la variable cuenta total. Nos sirve para comparar directamente los distintos valores que observamos los datos según el orden que ocupan.\n\n\n\n\n\n\nCuantiles de datos numéricos\n\n\n\nEl cuantil \\(f\\) de un bonche de datos numéricos es el valor \\(q(f)\\), en la escala de medición de nuestros datos, tal que aproximadamente una fracción \\(f\\) de los datos está por abajo de \\(q(f)\\).\n\nAl cuantil \\(f=0.5\\) le llamamos la mediana.\nA los cuantiles \\(f=0.25\\) y \\(f=0.75\\) les llamamos cuantiles inferior y superior.\n\n\n\nDispersión y valores centrales\n\nEl rango de datos va de unos 3 dólares hasta 50 dólares\nLos valores centrales (del cuantil 0.25 al 0.75, por ejemplo), están entre unos 13 y 25 dólares\nPodemos usar el cuantil 0.5 (mediana) para dar un valor central de esta distribución, que está alrededor de 18 dólares.\n\nY podemos dar resúmenes más refinados si es necesario\n\nEl cuantil 0.95 es de unos 35 dólares - sólo 5% de las cuentas son de más de 35 dólares\nEl cuantil 0.05 es de unos 8 dólares - sólo 5% de las cuentas son de 8 dólares o menos.\n\nFinalmente, la forma de la gráfica se interpreta usando su pendientes, haciendo comparaciones de diferentes partes de la gráfica:\n\nEntre los cuantiles 0.2 y 0.5 es donde existe mayor densidad de datos: la pendiente es baja, lo que significa que al avanzar en los cuantiles, los valores observados no cambian mucho.\nCuando la pendiente es alta, quiere decir que los datos tienen más dispersión local o están más separados.\n\nY podemos considerar qué sucede en las colas de la distribucion:\n\nLa distribución de valores tiene asimetría: el 10% de las cuentas más altas tiene considerablemente más dispersión que el 10% de las cuentas más bajas. A veces decimos que la cola de la derecha es más larga que la cola de la izquierda\n\nEn algunos casos, es más natural hacer un histograma, donde dividimos el rango de la variable en cubetas o intervalos (en este caso de igual longitud), y graficamos cuántos datos caen en cada cubeta:\n\n\n\n\n\nEs una gráfica más popular, pero perdemos cierto nivel de detalle, y distintas particiones resaltan distintos aspectos de los datos.\nFinalmente, una gráfica más compacta que resume la gráfica de cuantiles o el histograma es el diagrama de caja y brazos. Mostramos dos versiones, la clásica de Tukey (T) y otra versión menos común de Spear/Tufte (ST):\n\nlibrary(ggthemes)\ncuartiles <- quantile(cuenta$cuenta_total)\ncuartiles\n\n     0%     25%     50%     75%    100% \n 3.0700 13.3475 17.7950 24.1275 50.8100 \n\ng_1 <- ggplot(cuenta, aes(x = f, y = cuenta_total)) + \n  labs(subtitle = \"Gráfica de cuantiles: Cuenta total\") +\n  geom_hline(yintercept = cuartiles[2], colour = \"gray\") + \n  geom_hline(yintercept = cuartiles[3], colour = \"gray\") +\n  geom_hline(yintercept = cuartiles[4], colour = \"gray\") +\n  geom_point(alpha = 0.5) + geom_line() \ng_2 <- ggplot(cuenta, aes(x = factor(\"ST\", levels =c(\"ST\")), y = cuenta_total)) + \n  geom_tufteboxplot() +\n  labs(subtitle = \" \") +  xlab(\"\") + ylab(\"\")\ng_3 <- ggplot(cuenta, aes(x = factor(\"T\"), y = cuenta_total)) + geom_boxplot() +\n  labs(subtitle = \" \") +  xlab(\"\") + ylab(\"\")\ng_4 <- ggplot(cuenta, aes(x = factor(\"P\"), y = cuenta_total)) + geom_jitter(height = 0, width =0.2, alpha = 0.5) +\n  labs(subtitle = \" \") +  xlab(\"\") + ylab(\"\")\ng_1 + g_2 + g_3 + g_4 +\n  plot_layout(widths = c(8, 2, 2, 2))\n\n\n\n\nNota: Hay varias maneras de definir los cuantiles. Si tenemos \\(n\\) datos, podríamos poner \\(q(4/n)\\) como el cuarto dato (ordenando del más chico al más grande), y así sucesivamente. Esto implica por ejemplo que \\(q(1)\\) está definido como el valor más grande de los datos, y esto no es tan coveniente cuando trabajamos con modelos de probabilidad. Por eso preferimos definir al \\(k\\)-ésimo dato como el cuantil \\(q(\\frac{k - 0.5}{n})\\). Para las gráficas que estamos haciendo por el momento esto no es muy importante."
  },
  {
    "objectID": "numericos.html#media-y-desviación-estándar",
    "href": "numericos.html#media-y-desviación-estándar",
    "title": "1  Datos numéricos",
    "section": "1.2 Media y desviación estándar",
    "text": "1.2 Media y desviación estándar\nOtras medidas más comunes de localización y dispersión para conjuntos de datos son media y desviación estándar muestral.\nLa media de un conjunto de datos \\(x_1,\\ldots, x_n\\) es\n\\[\\bar{x} = \\frac{1}{n}\\sum x_i\\]\ny la desviación estándar es\n\\[\\hat{\\sigma} =\\sqrt{\\frac{1}{n}\\sum (x_i - \\bar{x})^2}\\]\nEn general, no son muy apropiadas para iniciar el análisis exploratorio, pues:\n\nSon medidas más difíciles de interpretar y explicar que los cuantiles. En este sentido, son medidas especializadas. Como ejercicio, intenta explicar intuitivamente qué es la media. Después prueba con la desviación estándar.\nNo son resistentes a valores atípicos o erróneos. Su falta de resistencia los vuelve poco útiles en las primeras etapas de limpieza y descripción.\n\nSin embargo,\n\nLa media y desviación estándar son computacionalmente convenientes, y para el trabajo de modelado, por ejemplo, tienen ventajas claras (cuando se cumplen supuestos). Por lo tanto regresaremos a estas medidas una vez que estudiemos modelos de probabilidad básicos.\nMuchas veces, ya sea por tradición, o por razones específicas, conviene usar estas medidas conocidas (o alguna variación). Por ejemplo cuando estamos estimando cantidades como totales, por ejemplo."
  },
  {
    "objectID": "numericos.html#comparando-grupos-con-variables-numéricas",
    "href": "numericos.html#comparando-grupos-con-variables-numéricas",
    "title": "1  Datos numéricos",
    "section": "1.3 Comparando grupos con variables numéricas",
    "text": "1.3 Comparando grupos con variables numéricas"
  },
  {
    "objectID": "numericos.html#ejemplo-precios-de-casas",
    "href": "numericos.html#ejemplo-precios-de-casas",
    "title": "1  Datos numéricos",
    "section": "Ejemplo: precios de casas",
    "text": "Ejemplo: precios de casas\nConsideramos datos de precios de ventas de la ciudad de Ames, Iowa. Nos interesa entender la variación del precio de las casas.\n\n\n\nCalculamos primeros unos cuantiles de los precios de las casas:\n\nquantile(casas |> pull(precio_miles)) \n\n   0%   25%   50%   75%  100% \n 37.9 132.0 165.0 215.0 755.0 \n\n\nUna primera comparación que podemos hacer es considerar las distintas zonas de la ciudad. Podemos usar diagramas de caja y brazos para comparar precios en distintas zonas de la ciudad:\n\nggplot(casas, aes(x = nombre_zona, y = precio_miles)) + geom_boxplot() + coord_flip()\n\n\n\n\nNótese que de cada zona, los datos tienen una cola derecha más larga que la izquierda, e incluso hay valores extremos en la cola derecha que exceden el rango de variación usual. Una razón por la que puede suceder esto es que haya características particulares que agregan valor considerable a una casa, por ejemplo, el tamaño, una alberca, etc.\nEn primer lugar, podemos considerar el área de las casas. En lugar de graficar el precio, graficamos el precio por metro cuadrado, por ejemplo:\n\n\n\n\nggplot(casas, aes(x = nombre_zona, y = precio_m2)) + geom_boxplot() + coord_flip()\n\n\n\n\nNótese ahora que la variación alrededor de la media es mucho más simétrica, y ya no vemos tantos datos extremos. Aún más, la variación dentro de cada zona parece ser similar, y podríamos describir restos datos de la siguiente forma:\nCuantificamos la variación que observamos de zona a zona y la variación que hay dentro de zonas. La variación que vemos entre las medianas de la zona es:\n\ncasas |> group_by(nombre_zona) |> \n  summarise(mediana_zona = median(precio_m2)) |> \n  pull(mediana_zona) |> quantile() |> round()\n\n  0%  25%  50%  75% 100% \n 963 1219 1298 1420 1725 \n\n\nY las variaciones con respecto a las medianas dentro de cada zona, agrupadas, se resume como:\n\nquantile(casas |> group_by(nombre_zona) |> \n  mutate(residual = precio_m2 - median(precio_m2)) |> \n  pull(residual)) |> round()\n\n  0%  25%  50%  75% 100% \n-765 -166    0  172 1314 \n\n\nNótese que este último paso tiene sentido pues la variación dentro de las zonas, en términos de precio por metro cuadrado, es similar. Esto no lo podríamos hacer de manera efectiva si hubiéramos usado el precio de las casas sin ajustar por su tamaño.\nY vemos que la mayor parte de la variación del precio por metro cuadrado ocurre dentro de cada zona, una vez que controlamos por el tamaño de las casas. La variación dentro de cada zona es aproximadamente simétrica, aunque la cola derecha es ligeramente más larga con algunos valores extremos.\nPodemos seguir con otro indicador importante: la calificación de calidad de los terminados de las casas. Como primer intento podríamos hacer:\n\n\n\n\n\nLo que indica que las calificaciones de calidad están distribuidas de manera muy distinta a lo largo de las zonas, y que probablemente no va ser simple desentrañar qué variación del precio se debe a la zona y cuál se debe a la calidad."
  },
  {
    "objectID": "numericos.html#distribuciones-sesgadas-y-atípicos",
    "href": "numericos.html#distribuciones-sesgadas-y-atípicos",
    "title": "1  Datos numéricos",
    "section": "1.4 Distribuciones sesgadas y atípicos",
    "text": "1.4 Distribuciones sesgadas y atípicos\nEn algunos casos tenemos que trabajar con mediciones que tienen una cola (usualmente la derecha) mucho más larga que la otra. Veamos cuáles son consecuencias típicas.\nConsideremos por ejemplos una muestra de los datos de ENIGH 2018\n\nenigh <- read_csv(\"./datos/enigh-ejemplo.csv\")\n\nY los deciles de ingreso son\n\nenigh <- mutate(enigh, ingreso_mensual_miles = INGTOT / 3000)\n\nenigh |> \n  summarise(\n    f = seq(0, 1, 0.1),\n    cuantiles_ingreso =  quantile(ingreso_mensual_miles, probs = seq(0, 1, 0.1))) |> \n  kable(digits = 2) |> \n  kable_paper(full_width = FALSE)\n\n\n\n \n  \n    f \n    cuantiles_ingreso \n  \n \n\n  \n    0.0 \n    0.81 \n  \n  \n    0.1 \n    2.58 \n  \n  \n    0.2 \n    3.86 \n  \n  \n    0.3 \n    5.53 \n  \n  \n    0.4 \n    6.75 \n  \n  \n    0.5 \n    8.27 \n  \n  \n    0.6 \n    9.99 \n  \n  \n    0.7 \n    12.95 \n  \n  \n    0.8 \n    16.20 \n  \n  \n    0.9 \n    22.18 \n  \n  \n    1.0 \n    317.53 \n  \n\n\n\n\n\ndonde podemos ver cómo cuando nos movemos a deciles más altos, la dispersión aumenta. Existen algunos valores muy grandes. Un histograma no funciona muy bien con estos datos.\n\nggplot(enigh, aes(x = ingreso_mensual_miles)) + geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nSi filtramos los valores muy grandes, de todas formas encontramos una forma similar con una cola larga a la derecha:\n\nggplot(enigh |> filter(ingreso_mensual_miles < 90), \n       aes(x = ingreso_mensual_miles)) + geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nNótese que la media de estos datos no es un resúmen muy útil, porque es difícil de interpretar. Por los valores grandes, la media es considerablemente más alta que la mediana:\n\nenigh |> \n  summarise(\n    media = mean(ingreso_mensual_miles),\n    mediana =  quantile(ingreso_mensual_miles, probs = 0.5)) |> \n  kable(digits = 2)\n\n\n\n \n  \n    media \n    mediana \n  \n \n\n  \n    12.04 \n    8.27 \n  \n\n\n\n\n\nEsta es otra razón para incluir información de cuantiles en la etapa descriptiva. Por ejemplo, podríamos resumir:\n\nenigh |> \n  summarise(\n    f = c(\"min\", 0.5, \"0.50\",  0.95, \"max\"),\n    cuantiles_ingreso =  quantile(ingreso_mensual_miles, probs = c(0, 0.05, 0.5, 0.95, 1))) |> \n  kable(digits = 2)  |> \n  kable_paper(full_width = FALSE)\n\n\n\n \n  \n    f \n    cuantiles_ingreso \n  \n \n\n  \n    min \n    0.81 \n  \n  \n    0.5 \n    1.92 \n  \n  \n    0.50 \n    8.27 \n  \n  \n    0.95 \n    32.24 \n  \n  \n    max \n    317.53 \n  \n\n\n\n\n\nPara obtener una gŕafica más informativa, podemos utilizar una escala logarítmica. El logaritmo de los ingresos es más fácil de describir y veremos también más fácil de trabajar.\n\nggplot(enigh, \n       aes(x = ingreso_mensual_miles)) + \n  geom_histogram(binwidth = 0.12) +\n  scale_x_log10(breaks = c(1, 2, 4, 8, 16, 32, 64, 128, 256)) +\n  xlab(\"Ingreso mensual (miles)\")"
  },
  {
    "objectID": "numericos.html#factor-y-respuesta-numéricos",
    "href": "numericos.html#factor-y-respuesta-numéricos",
    "title": "1  Datos numéricos",
    "section": "1.5 Factor y respuesta numéricos",
    "text": "1.5 Factor y respuesta numéricos\nEn las secciones anteriores vimos cómo describir “bonches” de datos numéricos y categóricos. Adicionalmente, vimos cómo usar esas técnicas para comparar las descripciones a lo largo de varios subconjuntos de los datos.\nEn estos casos, muchas veces llamamos factor a la variables que forma los grupos, y respuesta a la variable que estamos comparando. Por ejemplo, en el caso de tomadores de té comparamos uso de complementos (respuesta) a lo largo de consumidores de distintos tipos de té (factor) En el caso de los precios de las casas comparamos el precio de las casas (respuesta) dependiendo del vecindario (factor) dónde se encuentran.\nCuando tenemos una factor numérico y una respuesta numérica podemos comenzar haciendo diagramas de dispersión. Por ejemplo,"
  },
  {
    "objectID": "numericos.html#ejemplo-cuenta-total-y-propina",
    "href": "numericos.html#ejemplo-cuenta-total-y-propina",
    "title": "1  Datos numéricos",
    "section": "Ejemplo: cuenta total y propina",
    "text": "Ejemplo: cuenta total y propina\n\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(kableExtra)\n# usamos los datos tips del paquete reshape2\npropinas <- read_csv(\"./datos/propinas.csv\")\n\nPodríamos comenzar haciendo:\n\nggplot(propinas, aes(x = cuenta_total, y = propina)) +\n   geom_point() + geom_rug(colour = \"salmon\", alpha = 0.5)\n\n\n\n\nAhora queremos comparar la distribución de propina (respuesta) para distintos niveles del factor (cuenta_total). Por ejemplo, ¿cómo se compara propina cuando la cuenta es de 15 dólares vs 30 dólares?\n\nggplot(propinas, aes(x = cuenta_total, y = propina)) +\n   geom_vline(xintercept = c(15, 30), colour = \"red\") +\n   geom_point() \n\n\n\n\nVemos que los datos de propinas alrededor de 30 dólares están centrados en valores más grandes que en el nivel de 15 dólares, y también que hay más dispersión en el nivel de 30 dólares. Sin embargo, vemos que tenemos un problema: existen realmente muy pocos datos que tengan exactamente 15 o 30 dólares de cuenta. La estrategia es entonces considerar qué sucede cuando la cuenta está alrededor de 15 o alrededor de 30 dólares, donde alrededor depende del problema particular y de cuántos datos tenemos:\n\nggplot(propinas, aes(x = cuenta_total, y = propina)) +\n   geom_ribbon(aes(xmin = 13, xmax = 17), fill = \"salmon\", alpha = 0.5) +\n   geom_ribbon(aes(xmin = 28, xmax = 32), fill = \"salmon\", alpha = 0.5) +\n   geom_point() \n\n\n\n\nConsiderando estos grupos de datos, podemos describir de las siguiente forma, por ejemplo:\n\npropinas |> \n   mutate(grupo = cut(cuenta_total,  breaks = c(0, 13, 17, 28, 32))) |> \n   filter(grupo %in% c(\"(13,17]\", \"(28,32]\")) |> \n   group_by(grupo) |> \n   summarise(\n      n = n(),\n      q10 = quantile(propina, 0.10),\n      mediana = quantile(propina, 0.5),\n      q90 = quantile(propina, 0.90),\n      rango_cuartiles = quantile(propina, 0.75) - quantile(propina, 0.25)) |> \n   kable(digits = 2)  |> \n  kable_paper(full_width = FALSE)\n\n\n\n \n  \n    grupo \n    n \n    q10 \n    mediana \n    q90 \n    rango_cuartiles \n  \n \n\n  \n    (13,17] \n    57 \n    1.85 \n    2.47 \n    3.49 \n    1.0 \n  \n  \n    (28,32] \n    16 \n    2.02 \n    3.69 \n    5.76 \n    2.2 \n  \n\n\n\n\n\nConde confirmamos que el nivel general de propinas es más alto alrededor de cuentas de total 30 que de total 15, y la dispersión también es mayor. Podríamos hacer un diagrama de caja y brazos también."
  },
  {
    "objectID": "numericos.html#suavizadores-locales",
    "href": "numericos.html#suavizadores-locales",
    "title": "1  Datos numéricos",
    "section": "1.6 Suavizadores locales",
    "text": "1.6 Suavizadores locales\nEl enfoque del ejemplo anterior puede ayudar en algunos casos nuestra tarea descriptiva, pero quisiéramos tener un método más general y completo para entender cómo es una respuesta numérica cuando el factor es también numérico.\nEn este caso, podemos hacer por ejemplo medias o medianas locales. La idea general es, en términos de nuestro ejemplo de propinas:\n\nQueremos producir un resumen en un valor de cuenta total \\(x\\).\nConsideramos valores de propina asociados a cuentas totales en un intervalo \\([x-e, x+e]\\).\nCalculamos estadísticas resumen en este rango para la respuesta\nUsualmente también ponderamos más alto valores que están cerca de \\(x\\) y ponderamos menos valores más lejanos a \\(x\\)\n\nEste tipo de suavizadores se llaman a veces suavizadores loess (ver (Cleveland 1993)).\nPor ejemplo,\n\nggplot(propinas, aes(x = cuenta_total, y = propina)) +\n   geom_ribbon(aes(xmin = 13, xmax = 17), fill = \"salmon\", alpha = 0.15) +\n   geom_ribbon(aes(xmin = 28, xmax = 32), fill = \"salmon\", alpha = 0.15) +\n   geom_point() +\n   geom_smooth(method = \"loess\", span = 0.5, \n               method.args = list(family = \"symmetric\", degree = 1), se = FALSE) \n\n`geom_smooth()` using formula 'y ~ x'\n\n\n\n\n# symmetric es un método robusto iterativo, que reduce el peso de atípicos\n\nEl parametro span controla el tamaño de la ventana de datos que se toma en cada punto. Nótese como alrededor de 15 y 30 los valores por donde pasa el suavizador son similares a las medianas que escribimos arriba.\nPodemos ajustar en cada ventana tambien rectas de minimos cuadrados, y obtener un suavizador de tipo lineal. En la siguiente gráfica mostramos cómo funciona este suavizador para distintos tamaños de ventanas (span)\n\n\n\nSuavizador loess\n\n\n\n\n\n\n\n\nTip\n\n\n\nLos suavizadores loess tienen como fin mostrar alrededor de qué valor de distribuye la respuesta (eje vertical) para distintos valores del factor (eje horizontal). Se escoge span suficientemente baja de forma que mostremos patrones claros en los datos y casi no capturemos variación debida a los tamaños de muestra chicos.\n\n\nEn la animación anterior, un valor de span de 0.15 funciona aprpiadamente, y uno de 0.05 es demasiado bajo y uno de 1.0 es demasiado alto. Es importante explorar con el valor de span pues depende de cuántos datos tenemos y cómo es su dispersión.\nPodemos también mostrar estimaciones de medianas y cuantiles de la siguiente forma (nota: es necesario escoger lambda con cuidado, cuanto más alto sea lambda más suave es la curva obtenida):\n\nggplot(propinas, aes(x = cuenta_total, y = propina)) +\n   geom_ribbon(aes(xmin = 13, xmax = 17), fill = \"salmon\", alpha = 0.15) +\n   geom_ribbon(aes(xmin = 28, xmax = 32), fill = \"salmon\", alpha = 0.15) +\n   geom_point() +\n   geom_quantile(method = \"rqss\", lambda = 15, quantiles = c(0.10, 0.5, 0.90)) +\n   scale_y_continuous(breaks = seq(0, 10, 1)) +\n   xlab(\"Propina (dólares)\")\n\nSmoothing formula not specified. Using: y ~ qss(x, lambda = 15)\n\n\n\n\n\nFinalmente, entendimiento de los datos no permite también hacer gráficas más útiles. En este ejemplo particular podría por ejemplo calcular el porcentaje de la propina sobre la cuenta total:\n\npropinas <- propinas |> mutate(propinas, pct_propina = propina / cuenta_total) \npropinas_2 <- propinas |> \n  filter(pct_propina < 0.70)  |> \n  mutate(grupo = cut(num_personas, c(1, 3, 10), include.lowest = TRUE)) \nquantile(propinas_2 |> pull(pct_propina)) |> round(2)\n\n  0%  25%  50%  75% 100% \n0.04 0.13 0.15 0.19 0.42 \n\nggplot(propinas, aes(x = cuenta_total, y = pct_propina)) +\n   geom_point() +\n   scale_y_continuous(breaks = seq(0,1, 0.05)) +\n   geom_quantile(method = \"rqss\", \n                 lambda = 20, quantiles = c(0.10, 0.5, 0.90)) \n\n\n\n\nObserva que la descripción es más simple que si usamos propina cruda y cuenta.\n\nPara cuentas chicas, el porcentaje de propina puede ser muy alto (aún cuando la propina en sí no es tan grande):\n\n\nfilter(propinas, pct_propina > 0.30) |> \n  arrange(desc(pct_propina)) |> \n  kable(digits = 2)  |> \n  kable_paper(full_width = FALSE)\n\n\n\n \n  \n    cuenta_total \n    propina \n    fumador \n    dia \n    momento \n    num_personas \n    pct_propina \n  \n \n\n  \n    7.25 \n    5.15 \n    Si \n    Dom \n    Cena \n    2 \n    0.71 \n  \n  \n    9.60 \n    4.00 \n    Si \n    Dom \n    Cena \n    2 \n    0.42 \n  \n  \n    3.07 \n    1.00 \n    Si \n    Sab \n    Cena \n    1 \n    0.33 \n  \n\n\n\n\n\n\nPara cuentas relativamente chicas (10 dólares, el porcentaje de propina está por encima de 15%). Este porcentaje tiende a reducirse a valores 10% y 15% para cuentas más grandes.\nExiste variación considerable alrededor de estos valores centrales. El rango entre los deciles extremos es aproximadamente de 5 puntos porcentuales.\n\nO de manera más resumida:\n\nLa mediana de propinas está ligeramente por arriba de 15% para cuantas relativamente chicas. Esta mediana baja hasta alrededor de 10%-15% para cuentas más grandes (más de 40 dólares)\nLa mitad de las propinas no varía más de unos 5 puntos porcentuales alrededor de estas medianas.\nExisten propinas atípicas: algunas muy bajas de 1 dólar, muy por debajo del 15%, y ocasionalmente algunas muy altas en porcentaje. Estas últimas ocurren ocasinalmente especialmente en cuentas chicas (por ejemplo, una propina de 1 dólar en una cuenta de 3 dólares).\n\nSi dividimos por tamaño de grupo, vemos información adicional: la reducción proporcional de propina parece no ocurrir en grupos más grandes (más personas en la mesa), donde la mediana de propinas se mantiene en 15%.\n\npropinas <- propinas |> mutate(propinas, pct_propina = propina / cuenta_total) \npropinas_2 <- propinas |> \n  filter(pct_propina < 0.70)  |> \n  mutate(grupo = cut(num_personas, c(1, 3, 10), include.lowest = TRUE)) \nquantile(propinas_2 |> pull(pct_propina)) |> round(2)\n\n  0%  25%  50%  75% 100% \n0.04 0.13 0.15 0.19 0.42 \n\nggplot(propinas_2, aes(x = cuenta_total, y = pct_propina)) +\n   geom_point() +\n   scale_y_continuous(breaks = seq(0,1, 0.05)) +\n   geom_quantile(method = \"rqss\", \n                 lambda = 30, quantiles = c(0.10, 0.5, 0.90)) +\n  facet_wrap(~ grupo) \n\n\n\n\n\nEs razonable cortar por número de grupo, pues esta variable afecta tanto a la cuenta total (grupos mayores tienden a gastar más) como al porcentaje de propina (grupos mayores tienen que ponerse de acuerdo con la propina, la propina se divide en más personas, pueden tener más problemas con el servicio, etc).\n\nEste es otro ejemplo de una gráfica de este tipo (usando regresión cuantílica):\n\n\n\nCrecimiento de bebés\n\n\n\n\n\n\nCleveland, William S. 1993. Visualizing Data. Hobart Press."
  },
  {
    "objectID": "categoricos.html",
    "href": "categoricos.html",
    "title": "2  Datos categóricos",
    "section": "",
    "text": "En esta sección mostraremos cómo hacer distintos tipos de resúmenes para mediciones individuales. Consideraremos también el uso de estas descripciones para comparar distintos grupos (o bonches de datos, como les llamaba Tukey), aplicando repetidamente los mismos resúmenes a lo largo de esos distintos grupos."
  },
  {
    "objectID": "categoricos.html#datos-categóricos-y-tablas",
    "href": "categoricos.html#datos-categóricos-y-tablas",
    "title": "2  Datos categóricos",
    "section": "2.1 Datos categóricos y tablas",
    "text": "2.1 Datos categóricos y tablas\nUna medición categórica es una que toma sus valores posibles en un conjunto que no es numérico. Consideremos los siguiente datos de 300 tomadores de té (Lê, Josse, y Husson (2008)):\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(kableExtra)\n\n\n\n\n\n \n  \n    id \n    tipo \n    complementos \n    azucar \n    presentacion \n    precio \n    edad \n  \n \n\n  \n    293 \n    earl_grey \n    leche \n    con_azúcar \n    bolsa \n    de_marca \n    53 \n  \n  \n    264 \n    earl_grey \n    solo \n    con_azúcar \n    mixto \n    variable \n    29 \n  \n  \n    164 \n    negro \n    solo \n    sin_azúcar \n    mixto \n    de_marca \n    21 \n  \n  \n    279 \n    negro \n    solo \n    sin_azúcar \n    mixto \n    variable \n    21 \n  \n  \n    148 \n    negro \n    otros \n    con_azúcar \n    bolsa \n    fino \n    72 \n  \n  \n    66 \n    negro \n    otros \n    sin_azúcar \n    mixto \n    fino \n    62 \n  \n  \n    217 \n    negro \n    solo \n    sin_azúcar \n    mixto \n    variable \n    28 \n  \n  \n    15 \n    negro \n    leche \n    sin_azúcar \n    bolsa \n    fino \n    65 \n  \n  \n    154 \n    verde \n    solo \n    sin_azúcar \n    bolsa \n    de_marca \n    49 \n  \n  \n    99 \n    negro \n    leche \n    con_azúcar \n    mixto \n    variable \n    33 \n  \n\n\n\n\n\nMediciones como tipo, presentación o azucar son variables categóricas. Desde el punto de vista univariado, generalmente no es necesario resumir, sino simplemente agrupar y contar cuántas veces ocurre cada categoría. Por ejemplo\n\ntabla_1 <- te_tbl |> count(tipo) |> \n   arrange(desc(n))\ntabla_1 |> kable() |> kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tipo \n    n \n  \n \n\n  \n    earl_grey \n    193 \n  \n  \n    negro \n    74 \n  \n  \n    verde \n    33 \n  \n\n\n\n\n\nUsualmente es más útil reportar la porporción o porcentaje de casos por categoría\n\ntabla_2 <- te_tbl |> \n   count(tipo) |> \n   mutate(n_total = sum(n), prop = n / n_total) |> \n   select(tipo, n_total, prop) |> \n   mutate(across(where(is.numeric), round, 2)) |> \n   arrange(desc(prop))\ntabla_2 |> kable() |> kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tipo \n    n_total \n    prop \n  \n \n\n  \n    earl_grey \n    300 \n    0.64 \n  \n  \n    negro \n    300 \n    0.25 \n  \n  \n    verde \n    300 \n    0.11 \n  \n\n\n\n\n\nPodemos hacer varias variables juntas de la siguiente manera:\n\nperfiles_col_tbl <- te_tbl |> select(id, tipo, complementos, presentacion, azucar) |> \n   pivot_longer(cols = tipo:azucar, names_to = \"variable\", values_to = \"valor\") |> \n   count(variable, valor) |> \n   group_by(variable) |> \n   mutate(n_total = sum(n), prop = n / n_total) |>\n   mutate(prop = round(prop, 2)) |> \n   arrange(desc(prop), .by_group = TRUE)\nperfiles_col_tbl |> kable() |> kable_paper(full_width = FALSE)\n\n\n\n \n  \n    variable \n    valor \n    n \n    n_total \n    prop \n  \n \n\n  \n    azucar \n    sin_azúcar \n    155 \n    300 \n    0.52 \n  \n  \n    azucar \n    con_azúcar \n    145 \n    300 \n    0.48 \n  \n  \n    complementos \n    solo \n    195 \n    300 \n    0.65 \n  \n  \n    complementos \n    leche \n    63 \n    300 \n    0.21 \n  \n  \n    complementos \n    limón \n    33 \n    300 \n    0.11 \n  \n  \n    complementos \n    otros \n    9 \n    300 \n    0.03 \n  \n  \n    presentacion \n    bolsa \n    170 \n    300 \n    0.57 \n  \n  \n    presentacion \n    mixto \n    94 \n    300 \n    0.31 \n  \n  \n    presentacion \n    suelto \n    36 \n    300 \n    0.12 \n  \n  \n    tipo \n    earl_grey \n    193 \n    300 \n    0.64 \n  \n  \n    tipo \n    negro \n    74 \n    300 \n    0.25 \n  \n  \n    tipo \n    verde \n    33 \n    300 \n    0.11 \n  \n\n\n\n\n\nPara leer más fácil, imprimimos individualmente estas tablas, o hacemos algo como lo que sigue para mostrarlas todas juntas:\n\nperfiles_col_tbl |> \n   ungroup() |> \n   select(-variable, -n_total) |> \n   kable() |>  \n   pack_rows(index = table(perfiles_col_tbl$variable)) |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    valor \n    n \n    prop \n  \n \n\n  azucar\n\n    sin_azúcar \n    155 \n    0.52 \n  \n  \n    con_azúcar \n    145 \n    0.48 \n  \n  complementos\n\n    solo \n    195 \n    0.65 \n  \n  \n    leche \n    63 \n    0.21 \n  \n  \n    limón \n    33 \n    0.11 \n  \n  \n    otros \n    9 \n    0.03 \n  \n  presentacion\n\n    bolsa \n    170 \n    0.57 \n  \n  \n    mixto \n    94 \n    0.31 \n  \n  \n    suelto \n    36 \n    0.12 \n  \n  tipo\n\n    earl_grey \n    193 \n    0.64 \n  \n  \n    negro \n    74 \n    0.25 \n  \n  \n    verde \n    33 \n    0.11"
  },
  {
    "objectID": "categoricos.html#comparando-grupos-con-variables-categóricas",
    "href": "categoricos.html#comparando-grupos-con-variables-categóricas",
    "title": "2  Datos categóricos",
    "section": "2.2 Comparando grupos con variables categóricas",
    "text": "2.2 Comparando grupos con variables categóricas\nEste análisis generalmente es más interesante cuando comparamos grupos. Supongamos que nos interesa ver si existe una relación entre usar el tipo de té que toman estas personas y el uso de complementos como leche o limón. Naturalmente, escogeríamos dividir por tipo de té, y ver qué complementos se usan con cada uno:\n\nperfiles_col_tbl <- te_tbl |> count(complementos, tipo) |> \n   group_by(tipo) |> \n   mutate(prop = n / sum(n)) |>\n   group_by(complementos) |> \n   select(-n) |> \n   pivot_wider(names_from = tipo, values_from = prop, values_fill = 0)\nperfiles_col_tbl |>  kable(digits = 2, caption = \"Perfiles por columna\") |> \n  kable_paper(full_width = FALSE)\n\n\n\nPerfiles por columna\n \n  \n    complementos \n    earl_grey \n    negro \n    verde \n  \n \n\n  \n    leche \n    0.20 \n    0.26 \n    0.18 \n  \n  \n    limón \n    0.12 \n    0.09 \n    0.06 \n  \n  \n    otros \n    0.02 \n    0.08 \n    0.00 \n  \n  \n    solo \n    0.66 \n    0.57 \n    0.76 \n  \n\n\n\n\n\nComparando los perfiles de las columnas observamos variaciones interesantes: por ejemplo, los tomadores de Earl Grey tienden a usar más limón como complemento que otros grupos. Son resúmenes univariados que ahora comparamos a lo largo de grupos. Podemos hacer las comparaciones más simples si hacemos todas contra una columna marginal del uso general en la muestra de los distintos complementos\n\ncomp_tbl <- te_tbl |> count(complementos) |> mutate(total = n / sum(n))\nperfiles_col_tbl <- left_join(perfiles_col_tbl, comp_tbl) |> \n      arrange(desc(total)) |> \n      select(-n)\nperfiles_col_tbl |> kable(digits = 2) |> \n  kable_paper(full_width = FALSE)\n\n\n\n \n  \n    complementos \n    earl_grey \n    negro \n    verde \n    total \n  \n \n\n  \n    solo \n    0.66 \n    0.57 \n    0.76 \n    0.65 \n  \n  \n    leche \n    0.20 \n    0.26 \n    0.18 \n    0.21 \n  \n  \n    limón \n    0.12 \n    0.09 \n    0.06 \n    0.11 \n  \n  \n    otros \n    0.02 \n    0.08 \n    0.00 \n    0.03 \n  \n\n\n\n\n\nSi el tipo de té no influyera en los complementos, verías porcentajes muy similares en cada columna, pero vemos que hay coincidencias y diferencias entre los grupos de tomadores de té. Podemos expresar esto de manera simple calculando índices contra la columna de total:\n\nres_tbl <- perfiles_col_tbl |> \n   mutate(across(where(is.numeric), ~ .x / total)) |> \n   select(-total)\nres_tbl |> kable(digits = 2) |> \n  kable_paper(full_width = FALSE)\n\n\n\n \n  \n    complementos \n    earl_grey \n    negro \n    verde \n  \n \n\n  \n    solo \n    1.02 \n    0.87 \n    1.17 \n  \n  \n    leche \n    0.94 \n    1.22 \n    0.87 \n  \n  \n    limón \n    1.13 \n    0.86 \n    0.55 \n  \n  \n    otros \n    0.52 \n    2.70 \n    0.00 \n  \n\n\n\n\n\nValores por encima de 1 indican columnas por arriba de la población general, y análogamente para valores por debajo de uno. Estas cantidades pueden escribirse en términos porcentuales, o se les puede restar 1 para terminar como una variación porcentual del promedio. A estas cantidades se les llama residuales crudos:\n\nres_tbl <- perfiles_col_tbl |> \n   mutate(across(where(is.numeric) & !total, ~ .x / total - 1)) \nres_tbl |> kable(digits = 2) |> \n  kable_paper(full_width = FALSE)\n\n\n\n \n  \n    complementos \n    earl_grey \n    negro \n    verde \n    total \n  \n \n\n  \n    solo \n    0.02 \n    -0.13 \n    0.17 \n    0.65 \n  \n  \n    leche \n    -0.06 \n    0.22 \n    -0.13 \n    0.21 \n  \n  \n    limón \n    0.13 \n    -0.14 \n    -0.45 \n    0.11 \n  \n  \n    otros \n    -0.48 \n    1.70 \n    -1.00 \n    0.03 \n  \n\n\n\n\n\nPodemos finalmente marcar la tabla:\n\nres_tbl |>  mutate(across(where(is.numeric), round, 2)) |> \n   mutate(across(where(is.numeric) & ! total, \n                 ~ cell_spec(.x, color = ifelse(.x > 0.1, \"black\", \n                                         ifelse(.x < -0.1, \"red\", \"gray\"))))) |>\n   arrange(desc(total)) |> \n   kable(escape = FALSE, align = \"r\") |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    complementos \n    earl_grey \n    negro \n    verde \n    total \n  \n \n\n  \n    solo \n    0.02 \n    -0.13 \n    0.17 \n    0.65 \n  \n  \n    leche \n    -0.06 \n    0.22 \n    -0.13 \n    0.21 \n  \n  \n    limón \n    0.13 \n    -0.14 \n    -0.45 \n    0.11 \n  \n  \n    otros \n    -0.48 \n    1.7 \n    -1 \n    0.03 \n  \n\n\n\n\n\n\n\n\n\n\n\nPerfiles\n\n\n\nA este tipo de análisis de tablas cruzadas a veces se le llama análisis de perfiles columna. Nos permite entender cómo varía la distribución de la variable de los renglones según el grupo indicado por la columna.\n\nDesviaciones grandes en los residuales indican asociaciones fuertes entre la variable de los reglones y de las columnas\nRecordemos que este análisis aplica a la muestra de datos que tenemos. Columnas con pocos individuos tienden a mostrar más variación y debemos ser cuidadosos al generalizar.\n\n\n\nPodemos incluir también totales para ayudarnos a juzgar las variaciones:\n\n\n\n\n \n  \n    complementos \n    earl_grey \n    negro \n    verde \n    total \n  \n \n\n  \n     \n    193 \n    74 \n    33 \n    1.00 \n  \n  \n    solo \n    0.02 \n    -0.13 \n    0.17 \n    0.65 \n  \n  \n    leche \n    -0.06 \n    0.22 \n    -0.13 \n    0.21 \n  \n  \n    limón \n    0.13 \n    -0.14 \n    -0.45 \n    0.11 \n  \n  \n    otros \n    -0.48 \n    1.7 \n    -1 \n    0.03"
  },
  {
    "objectID": "categoricos.html#observación-perfiles-renglón-y-columna",
    "href": "categoricos.html#observación-perfiles-renglón-y-columna",
    "title": "2  Datos categóricos",
    "section": "2.3 Observación: perfiles renglón y columna",
    "text": "2.3 Observación: perfiles renglón y columna\nEl análisis también lo podemos hacer con los perfiles de los renglones. Los residuales crudos que usamos para interpretar son los mismos. La razón es la siguiente:\nPara los perfiles columna, si escribimos \\(n_{+j}\\) como los totales por columna, y \\(n_{i+}\\) los totales por renglón, tenemos que los perfiles columna son: \\[c_{i,j} = \\frac{n_{i,j}}{n_{+j}}\\] Escribimos también \\(c_i = \\frac{n_{i+}}{n}\\) y \\(r_j = \\frac{n_{+j}}{n}\\) como los porcentajes marginales por columna y por renglón respectivamente.\nLos residuales son entonces \\[r_{i,j} = \\frac{\\frac{n_{i,j}}{n_{+,j}}} { \\frac{n_{i,+}}{n}} - 1 = \\frac{p_{i,j} - r_ic_j}{r_ic_j}\\] Nótese que no importa entonces cómo comencemos el cálculo, por renglones o por columnas, el resultado es el mismo.\n\nDiscute qué sentido tiene comparar \\(p_{i,j}\\) contra \\(r_ic_j\\). ¿Qué interpretación tiene esta última cantidad?\n\nEn algunos casos se utilizan residuales estandarizados para hacer el análisis, que están dados por \\[ \\frac{p_{i,j} - r_ic_j}{\\sqrt{r_ic_j}}\\] Veremos más adelante cuál es la razón de esto: tiene que ver con inferencia y variabilidad muestral de perfiles y residuales, aunque el análisis básico que presentamos arriba generalmente es suficiente para extraer de manera clara patrones importantes en los datos."
  },
  {
    "objectID": "categoricos.html#visualización-de-tablas-cruzadas",
    "href": "categoricos.html#visualización-de-tablas-cruzadas",
    "title": "2  Datos categóricos",
    "section": "2.4 Visualización de tablas cruzadas",
    "text": "2.4 Visualización de tablas cruzadas\nPara tablas más grandes, muchas veces las técnicas que mostramos arriba no son suficientes para entender y presentar patrones importantes en los datos. En estos casos, buscamos reducir la dimensionalidad de los datos para poder presentarlos en una gráfica de dos dimensiones.\nPodemos utilizar análisis de correspondencias. A grandes rasgos (ver (Izenman 2009) para los detalles) buscamos una representación tal que:\n\nCada categoría de las columnas está representada por una flecha que sale del origen de nuestra gráfica\nCada categoría de los renglones está representada por un punto en nuestra gráfica\nSi proyectamos los puntos (renglones) sobre las direcciones de las columnas, entonces el tamaño de la proyección es lo más cercano posible a el residual correspondiente de las tablas del análisis mostrado arriba.\n\nPara construir esta gráfica, entonces, existe un proceso de optimización que busca representar lo más fielmente los residuales del análisis mostrado arriba en dos dimensiones, y de esta forma buscamos recuperar una buena parte de la información de los residuales de una manera más compacta."
  },
  {
    "objectID": "categoricos.html#ejemplo-tés-y-complementos",
    "href": "categoricos.html#ejemplo-tés-y-complementos",
    "title": "2  Datos categóricos",
    "section": "2.5 Ejemplo: tés y complementos",
    "text": "2.5 Ejemplo: tés y complementos\n\nlibrary(ca)\ncorr_te <- ca(table(te_tbl$complementos, te_tbl$tipo))\nplot(corr_te, map = \"rowgreen\", arrows = c(FALSE, TRUE))\n\n\n\n\nLa contribución de cada dimensión a la aproximación se indica en los ejes. Como vemos en la gráfica, y la suma de las contribuciones nos da la calidad de la representación, que en este caso es perfecta.\n\n\n\n\n\n\nTip\n\n\n\n\nEl análisis de correspondencias es un tema relativamente avanzado de estadística multivariada, y su definición precisa requiere de matemáticas más avanzadas (por ejemplo la descomposición en valores singulares).\nCualquier hallazgo obtenido en este tipo de análisis debe ser verificado en las tablas correspondientes de perfiles\nHay distintos tipos de gráficas (biplots) asociadas al análisis de correspondencias, que privilegian representar mejor a distintos tipos de características de los datos"
  },
  {
    "objectID": "categoricos.html#ejemplo-robo-en-tiendas",
    "href": "categoricos.html#ejemplo-robo-en-tiendas",
    "title": "2  Datos categóricos",
    "section": "2.6 Ejemplo: robo en tiendas",
    "text": "2.6 Ejemplo: robo en tiendas\nConsideramos los siguientes datos de robos en tiendas en Holanda por personas de distintas edades y genéros (Izenman (2009)). En este caso, las variables ya están cruzadas:\n\nhurto_tbl <- read_csv(\"./datos/hurto.csv\") |> \n   mutate(grupo = ifelse(grupo == \"-12 h\", \"01-12 h\", grupo),\n          grupo = ifelse(grupo == \"-12 m\", \"01-12 m\", grupo))\n\nRows: 18 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): grupo\ndbl (13): ropa, accesorios, tabaco, escritura, libros, discos, bienes, dulce...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhurto_tbl |> kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    grupo \n    ropa \n    accesorios \n    tabaco \n    escritura \n    libros \n    discos \n    bienes \n    dulces \n    juguetes \n    joyería \n    perfumes \n    herramientas \n    otros \n  \n \n\n  \n    01-12 h \n    81 \n    66 \n    150 \n    667 \n    67 \n    24 \n    47 \n    430 \n    743 \n    132 \n    32 \n    197 \n    209 \n  \n  \n    12-14 h \n    138 \n    204 \n    340 \n    1409 \n    259 \n    272 \n    117 \n    637 \n    684 \n    408 \n    57 \n    547 \n    550 \n  \n  \n    15-17 h \n    304 \n    193 \n    229 \n    527 \n    258 \n    368 \n    98 \n    246 \n    116 \n    298 \n    61 \n    402 \n    454 \n  \n  \n    18-20 h \n    384 \n    149 \n    151 \n    84 \n    146 \n    141 \n    61 \n    40 \n    13 \n    71 \n    52 \n    138 \n    252 \n  \n  \n    21-29 h \n    942 \n    297 \n    313 \n    92 \n    251 \n    167 \n    193 \n    30 \n    16 \n    130 \n    111 \n    280 \n    624 \n  \n  \n    30-39 h \n    359 \n    109 \n    136 \n    36 \n    96 \n    67 \n    75 \n    11 \n    16 \n    31 \n    54 \n    200 \n    195 \n  \n  \n    40-49 h \n    178 \n    53 \n    121 \n    36 \n    48 \n    29 \n    50 \n    5 \n    6 \n    14 \n    41 \n    152 \n    88 \n  \n  \n    50-64 h \n    137 \n    68 \n    171 \n    37 \n    56 \n    27 \n    55 \n    17 \n    3 \n    11 \n    50 \n    211 \n    90 \n  \n  \n    64+ h \n    45 \n    28 \n    145 \n    17 \n    41 \n    7 \n    29 \n    28 \n    8 \n    10 \n    28 \n    111 \n    34 \n  \n  \n    01-12 m \n    71 \n    19 \n    59 \n    224 \n    19 \n    7 \n    22 \n    137 \n    113 \n    162 \n    70 \n    15 \n    24 \n  \n  \n    12-14 m \n    241 \n    98 \n    111 \n    346 \n    60 \n    32 \n    29 \n    240 \n    98 \n    548 \n    178 \n    29 \n    58 \n  \n  \n    15-17 m \n    477 \n    114 \n    58 \n    91 \n    50 \n    27 \n    41 \n    80 \n    14 \n    303 \n    141 \n    9 \n    72 \n  \n  \n    18-20 m \n    436 \n    108 \n    76 \n    18 \n    32 \n    12 \n    32 \n    12 \n    10 \n    74 \n    70 \n    14 \n    67 \n  \n  \n    21-29 m \n    1180 \n    207 \n    132 \n    30 \n    61 \n    21 \n    65 \n    16 \n    12 \n    100 \n    104 \n    30 \n    157 \n  \n  \n    30-39 m \n    1009 \n    165 \n    121 \n    27 \n    43 \n    9 \n    74 \n    14 \n    31 \n    48 \n    81 \n    36 \n    107 \n  \n  \n    40-49 m \n    517 \n    102 \n    93 \n    23 \n    31 \n    7 \n    51 \n    10 \n    8 \n    22 \n    46 \n    24 \n    66 \n  \n  \n    50-64 m \n    488 \n    127 \n    214 \n    27 \n    57 \n    13 \n    79 \n    23 \n    17 \n    26 \n    69 \n    35 \n    64 \n  \n  \n    64+ m \n    173 \n    64 \n    215 \n    13 \n    44 \n    0 \n    39 \n    42 \n    6 \n    12 \n    41 \n    11 \n    55 \n  \n\n\n\n\n\nEsta tabla es más grande y difícil de entender tal cual está. Comenzamos por examinar las marginales:\n\nhurto_tbl |> \n   pivot_longer(cols = ropa:otros, names_to = \"producto\", values_to = \"n\") |> \n   group_by(producto) |> \n   summarise(n = sum(n)) |> \n   mutate(prop = n / sum(n)) |> \n   arrange(desc(prop)) |> \n   kable(digits = 2) |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    producto \n    n \n    prop \n  \n \n\n  \n    ropa \n    7160 \n    0.22 \n  \n  \n    escritura \n    3704 \n    0.11 \n  \n  \n    otros \n    3166 \n    0.10 \n  \n  \n    tabaco \n    2835 \n    0.09 \n  \n  \n    herramientas \n    2441 \n    0.07 \n  \n  \n    joyería \n    2400 \n    0.07 \n  \n  \n    accesorios \n    2171 \n    0.07 \n  \n  \n    dulces \n    2018 \n    0.06 \n  \n  \n    juguetes \n    1914 \n    0.06 \n  \n  \n    libros \n    1619 \n    0.05 \n  \n  \n    perfumes \n    1286 \n    0.04 \n  \n  \n    discos \n    1230 \n    0.04 \n  \n  \n    bienes \n    1157 \n    0.03 \n  \n\n\n\n\n\n\ngrupos_tbl <- hurto_tbl |> \n   pivot_longer(cols = ropa:otros, names_to = \"producto\", values_to = \"n\") |> \n   group_by(grupo) |> \n   summarise(n = sum(n)) |> \n   mutate(prop = n / sum(n)) |> \n   arrange(desc(prop))\ngrupos_tbl |> kable(digits = 2) |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    grupo \n    n \n    prop \n  \n \n\n  \n    12-14 h \n    5622 \n    0.17 \n  \n  \n    15-17 h \n    3554 \n    0.11 \n  \n  \n    21-29 h \n    3446 \n    0.10 \n  \n  \n    01-12 h \n    2845 \n    0.09 \n  \n  \n    21-29 m \n    2115 \n    0.06 \n  \n  \n    12-14 m \n    2068 \n    0.06 \n  \n  \n    30-39 m \n    1765 \n    0.05 \n  \n  \n    18-20 h \n    1682 \n    0.05 \n  \n  \n    15-17 m \n    1477 \n    0.04 \n  \n  \n    30-39 h \n    1385 \n    0.04 \n  \n  \n    50-64 m \n    1239 \n    0.04 \n  \n  \n    40-49 m \n    1000 \n    0.03 \n  \n  \n    18-20 m \n    961 \n    0.03 \n  \n  \n    01-12 m \n    942 \n    0.03 \n  \n  \n    50-64 h \n    933 \n    0.03 \n  \n  \n    40-49 h \n    821 \n    0.02 \n  \n  \n    64+ m \n    715 \n    0.02 \n  \n  \n    64+ h \n    531 \n    0.02 \n  \n\n\n\n\n\nIntentamos análisis de correspondencias para comparar los perfiles columna:\n\nhurto_df <- as.data.frame(hurto_tbl)\nrownames(hurto_df) <- hurto_tbl$grupo\nhurto_df$grupo <- NULL\ncorr_hurto <- ca(hurto_df)\ngrafica_datos <- plot(corr_hurto, map = \"rowgreen\", arrows = c(FALSE, TRUE))\n\n\n\n\n\nSegún esta gráfica, ¿qué categorias de productos están sobrerrepresentadas en cada grupo de edad? ¿Cómo tendrían que verse el análisis de perfiles columna?\n\nComo se aprecia, en la siguiente tabla, es difícil entender los patrones generales en los datos. Quitamos algunas columnas para imprimir más fácilmente\n\nperfiles_hurto_tbl <- hurto_tbl |> \n   pivot_longer(cols = ropa:otros, names_to = \"producto\", values_to = \"n\") |> \n   group_by(producto) |> \n   mutate(prop = n / sum(n)) |> \n   select(-n) |> \n   pivot_wider(names_from = producto, values_from = prop) \nperfiles_hurto_tbl |> \n   select(-bienes, -discos, -perfumes) |> \n   kable(digits = 2) |> \n   kable_styling(font_size = 12) |> \n   kable_paper()\n\n\n\n \n  \n    grupo \n    ropa \n    accesorios \n    tabaco \n    escritura \n    libros \n    dulces \n    juguetes \n    joyería \n    herramientas \n    otros \n  \n \n\n  \n    01-12 h \n    0.01 \n    0.03 \n    0.05 \n    0.18 \n    0.04 \n    0.21 \n    0.39 \n    0.06 \n    0.08 \n    0.07 \n  \n  \n    12-14 h \n    0.02 \n    0.09 \n    0.12 \n    0.38 \n    0.16 \n    0.32 \n    0.36 \n    0.17 \n    0.22 \n    0.17 \n  \n  \n    15-17 h \n    0.04 \n    0.09 \n    0.08 \n    0.14 \n    0.16 \n    0.12 \n    0.06 \n    0.12 \n    0.16 \n    0.14 \n  \n  \n    18-20 h \n    0.05 \n    0.07 \n    0.05 \n    0.02 \n    0.09 \n    0.02 \n    0.01 \n    0.03 \n    0.06 \n    0.08 \n  \n  \n    21-29 h \n    0.13 \n    0.14 \n    0.11 \n    0.02 \n    0.16 \n    0.01 \n    0.01 \n    0.05 \n    0.11 \n    0.20 \n  \n  \n    30-39 h \n    0.05 \n    0.05 \n    0.05 \n    0.01 \n    0.06 \n    0.01 \n    0.01 \n    0.01 \n    0.08 \n    0.06 \n  \n  \n    40-49 h \n    0.02 \n    0.02 \n    0.04 \n    0.01 \n    0.03 \n    0.00 \n    0.00 \n    0.01 \n    0.06 \n    0.03 \n  \n  \n    50-64 h \n    0.02 \n    0.03 \n    0.06 \n    0.01 \n    0.03 \n    0.01 \n    0.00 \n    0.00 \n    0.09 \n    0.03 \n  \n  \n    64+ h \n    0.01 \n    0.01 \n    0.05 \n    0.00 \n    0.03 \n    0.01 \n    0.00 \n    0.00 \n    0.05 \n    0.01 \n  \n  \n    01-12 m \n    0.01 \n    0.01 \n    0.02 \n    0.06 \n    0.01 \n    0.07 \n    0.06 \n    0.07 \n    0.01 \n    0.01 \n  \n  \n    12-14 m \n    0.03 \n    0.05 \n    0.04 \n    0.09 \n    0.04 \n    0.12 \n    0.05 \n    0.23 \n    0.01 \n    0.02 \n  \n  \n    15-17 m \n    0.07 \n    0.05 \n    0.02 \n    0.02 \n    0.03 \n    0.04 \n    0.01 \n    0.13 \n    0.00 \n    0.02 \n  \n  \n    18-20 m \n    0.06 \n    0.05 \n    0.03 \n    0.00 \n    0.02 \n    0.01 \n    0.01 \n    0.03 \n    0.01 \n    0.02 \n  \n  \n    21-29 m \n    0.16 \n    0.10 \n    0.05 \n    0.01 \n    0.04 \n    0.01 \n    0.01 \n    0.04 \n    0.01 \n    0.05 \n  \n  \n    30-39 m \n    0.14 \n    0.08 \n    0.04 \n    0.01 \n    0.03 \n    0.01 \n    0.02 \n    0.02 \n    0.01 \n    0.03 \n  \n  \n    40-49 m \n    0.07 \n    0.05 \n    0.03 \n    0.01 \n    0.02 \n    0.00 \n    0.00 \n    0.01 \n    0.01 \n    0.02 \n  \n  \n    50-64 m \n    0.07 \n    0.06 \n    0.08 \n    0.01 \n    0.04 \n    0.01 \n    0.01 \n    0.01 \n    0.01 \n    0.02 \n  \n  \n    64+ m \n    0.02 \n    0.03 \n    0.08 \n    0.00 \n    0.03 \n    0.02 \n    0.00 \n    0.00 \n    0.00 \n    0.02 \n  \n\n\n\n\n\n\nres_hurto_tbl <- left_join(perfiles_hurto_tbl, grupos_tbl |> rename(total = prop)) |> \n    select(-n) |> \n    select(-bienes, -discos, -perfumes) |> \n    mutate(across(where(is.numeric) & !total, ~ .x / total - 1)) |> \n    mutate(across(where(is.numeric), round, 2)) \n\nJoining, by = \"grupo\"\n\nres_hurto_tbl |> \n    mutate(across(where(is.numeric) & ! total, \n                 ~ cell_spec(.x, color = ifelse(.x > 0.2, \"black\", \n                                         ifelse(.x < -0.2, \"red\", \"gray\"))))) |>\n    select(-total) |> \n    kable(escape = FALSE) |>\n    kable_styling(font_size = 12) |> \n    kable_paper()\n\n\n\n \n  \n    grupo \n    ropa \n    accesorios \n    tabaco \n    escritura \n    libros \n    dulces \n    juguetes \n    joyería \n    herramientas \n    otros \n  \n \n\n  \n    01-12 h \n    -0.87 \n    -0.65 \n    -0.38 \n    1.1 \n    -0.52 \n    1.48 \n    3.52 \n    -0.36 \n    -0.06 \n    -0.23 \n  \n  \n    12-14 h \n    -0.89 \n    -0.45 \n    -0.29 \n    1.24 \n    -0.06 \n    0.86 \n    1.1 \n    0 \n    0.32 \n    0.02 \n  \n  \n    15-17 h \n    -0.6 \n    -0.17 \n    -0.25 \n    0.33 \n    0.48 \n    0.14 \n    -0.44 \n    0.16 \n    0.53 \n    0.34 \n  \n  \n    18-20 h \n    0.06 \n    0.35 \n    0.05 \n    -0.55 \n    0.77 \n    -0.61 \n    -0.87 \n    -0.42 \n    0.11 \n    0.57 \n  \n  \n    21-29 h \n    0.26 \n    0.31 \n    0.06 \n    -0.76 \n    0.49 \n    -0.86 \n    -0.92 \n    -0.48 \n    0.1 \n    0.89 \n  \n  \n    30-39 h \n    0.2 \n    0.2 \n    0.15 \n    -0.77 \n    0.42 \n    -0.87 \n    -0.8 \n    -0.69 \n    0.96 \n    0.47 \n  \n  \n    40-49 h \n    0 \n    -0.02 \n    0.72 \n    -0.61 \n    0.2 \n    -0.9 \n    -0.87 \n    -0.76 \n    1.51 \n    0.12 \n  \n  \n    50-64 h \n    -0.32 \n    0.11 \n    1.14 \n    -0.65 \n    0.23 \n    -0.7 \n    -0.94 \n    -0.84 \n    2.07 \n    0.01 \n  \n  \n    64+ h \n    -0.61 \n    -0.2 \n    2.19 \n    -0.71 \n    0.58 \n    -0.14 \n    -0.74 \n    -0.74 \n    1.83 \n    -0.33 \n  \n  \n    01-12 m \n    -0.65 \n    -0.69 \n    -0.27 \n    1.13 \n    -0.59 \n    1.39 \n    1.07 \n    1.37 \n    -0.78 \n    -0.73 \n  \n  \n    12-14 m \n    -0.46 \n    -0.28 \n    -0.37 \n    0.5 \n    -0.41 \n    0.9 \n    -0.18 \n    2.65 \n    -0.81 \n    -0.71 \n  \n  \n    15-17 m \n    0.49 \n    0.18 \n    -0.54 \n    -0.45 \n    -0.31 \n    -0.11 \n    -0.84 \n    1.83 \n    -0.92 \n    -0.49 \n  \n  \n    18-20 m \n    1.1 \n    0.71 \n    -0.08 \n    -0.83 \n    -0.32 \n    -0.8 \n    -0.82 \n    0.06 \n    -0.8 \n    -0.27 \n  \n  \n    21-29 m \n    1.58 \n    0.49 \n    -0.27 \n    -0.87 \n    -0.41 \n    -0.88 \n    -0.9 \n    -0.35 \n    -0.81 \n    -0.22 \n  \n  \n    30-39 m \n    1.64 \n    0.43 \n    -0.2 \n    -0.86 \n    -0.5 \n    -0.87 \n    -0.7 \n    -0.62 \n    -0.72 \n    -0.37 \n  \n  \n    40-49 m \n    1.39 \n    0.56 \n    0.09 \n    -0.79 \n    -0.37 \n    -0.84 \n    -0.86 \n    -0.7 \n    -0.67 \n    -0.31 \n  \n  \n    50-64 m \n    0.82 \n    0.56 \n    1.02 \n    -0.81 \n    -0.06 \n    -0.7 \n    -0.76 \n    -0.71 \n    -0.62 \n    -0.46 \n  \n  \n    64+ m \n    0.12 \n    0.36 \n    2.51 \n    -0.84 \n    0.26 \n    -0.04 \n    -0.85 \n    -0.77 \n    -0.79 \n    -0.2 \n  \n\n\n\n\n\n\nCompara tus conclusiones del mapa de correspondencias con esta información de los residuales\n\nNota adicionalmente que el ordenamiento de las categorías en la primera dimensión del mapa de correspondencias ayuda a interpretar:\n\nres_hurto_tbl |> select(\"grupo\", \"escritura\", \"juguetes\", \"dulces\", \"joyería\",\n                         \"herramientas\", \"otros\", \"libros\", \"tabaco\", \"accesorios\", \n                         \"ropa\") |> \n    mutate(across(where(is.numeric), \n                 ~ cell_spec(.x, color = ifelse(.x > 0.2, \"black\", \n                                         ifelse(.x < -0.2, \"red\", \"gray\"))))) |>\n    kable(escape = FALSE) |>\n    kable_styling(font_size = 12) |> \n    kable_paper()\n\n\n\n \n  \n    grupo \n    escritura \n    juguetes \n    dulces \n    joyería \n    herramientas \n    otros \n    libros \n    tabaco \n    accesorios \n    ropa \n  \n \n\n  \n    01-12 h \n    1.1 \n    3.52 \n    1.48 \n    -0.36 \n    -0.06 \n    -0.23 \n    -0.52 \n    -0.38 \n    -0.65 \n    -0.87 \n  \n  \n    12-14 h \n    1.24 \n    1.1 \n    0.86 \n    0 \n    0.32 \n    0.02 \n    -0.06 \n    -0.29 \n    -0.45 \n    -0.89 \n  \n  \n    15-17 h \n    0.33 \n    -0.44 \n    0.14 \n    0.16 \n    0.53 \n    0.34 \n    0.48 \n    -0.25 \n    -0.17 \n    -0.6 \n  \n  \n    18-20 h \n    -0.55 \n    -0.87 \n    -0.61 \n    -0.42 \n    0.11 \n    0.57 \n    0.77 \n    0.05 \n    0.35 \n    0.06 \n  \n  \n    21-29 h \n    -0.76 \n    -0.92 \n    -0.86 \n    -0.48 \n    0.1 \n    0.89 \n    0.49 \n    0.06 \n    0.31 \n    0.26 \n  \n  \n    30-39 h \n    -0.77 \n    -0.8 \n    -0.87 \n    -0.69 \n    0.96 \n    0.47 \n    0.42 \n    0.15 \n    0.2 \n    0.2 \n  \n  \n    40-49 h \n    -0.61 \n    -0.87 \n    -0.9 \n    -0.76 \n    1.51 \n    0.12 \n    0.2 \n    0.72 \n    -0.02 \n    0 \n  \n  \n    50-64 h \n    -0.65 \n    -0.94 \n    -0.7 \n    -0.84 \n    2.07 \n    0.01 \n    0.23 \n    1.14 \n    0.11 \n    -0.32 \n  \n  \n    64+ h \n    -0.71 \n    -0.74 \n    -0.14 \n    -0.74 \n    1.83 \n    -0.33 \n    0.58 \n    2.19 \n    -0.2 \n    -0.61 \n  \n  \n    01-12 m \n    1.13 \n    1.07 \n    1.39 \n    1.37 \n    -0.78 \n    -0.73 \n    -0.59 \n    -0.27 \n    -0.69 \n    -0.65 \n  \n  \n    12-14 m \n    0.5 \n    -0.18 \n    0.9 \n    2.65 \n    -0.81 \n    -0.71 \n    -0.41 \n    -0.37 \n    -0.28 \n    -0.46 \n  \n  \n    15-17 m \n    -0.45 \n    -0.84 \n    -0.11 \n    1.83 \n    -0.92 \n    -0.49 \n    -0.31 \n    -0.54 \n    0.18 \n    0.49 \n  \n  \n    18-20 m \n    -0.83 \n    -0.82 \n    -0.8 \n    0.06 \n    -0.8 \n    -0.27 \n    -0.32 \n    -0.08 \n    0.71 \n    1.1 \n  \n  \n    21-29 m \n    -0.87 \n    -0.9 \n    -0.88 \n    -0.35 \n    -0.81 \n    -0.22 \n    -0.41 \n    -0.27 \n    0.49 \n    1.58 \n  \n  \n    30-39 m \n    -0.86 \n    -0.7 \n    -0.87 \n    -0.62 \n    -0.72 \n    -0.37 \n    -0.5 \n    -0.2 \n    0.43 \n    1.64 \n  \n  \n    40-49 m \n    -0.79 \n    -0.86 \n    -0.84 \n    -0.7 \n    -0.67 \n    -0.31 \n    -0.37 \n    0.09 \n    0.56 \n    1.39 \n  \n  \n    50-64 m \n    -0.81 \n    -0.76 \n    -0.7 \n    -0.71 \n    -0.62 \n    -0.46 \n    -0.06 \n    1.02 \n    0.56 \n    0.82 \n  \n  \n    64+ m \n    -0.84 \n    -0.85 \n    -0.04 \n    -0.77 \n    -0.79 \n    -0.2 \n    0.26 \n    2.51 \n    0.36 \n    0.12 \n  \n\n\n\n\n\n\nOtras dimensiones\nEn el caso anterior, la calidad de la representación es cercana al 80%. Existen algunas desviaciones que la posiblemente la gŕafica no explica del todo, y algunas proyecciones son aproximadas. Podemos ver cómo se ven otras dimensiones de este análisis para entender desviaciones adicionales:\n\nplot(corr_hurto, dim = c(1, 3), map = \"rowgreen\", arrows = c(FALSE, TRUE))\n\n\n\n\n\n\n\n\nIzenman, A. J. 2009. Modern Multivariate Statistical Techniques: Regression, Classification, and Manifold Learning. Springer Texts en Statistics. Springer New York. https://books.google.com.mx/books?id=1CuznRORa3EC.\n\n\nLê, Sébastien, Julie Josse, y François Husson. 2008. «FactoMineR: An R Package for Multivariate Analysis». Journal of Statistical Software, Articles 25 (1): 1-18. https://doi.org/10.18637/jss.v025.i01."
  },
  {
    "objectID": "analisis-datos.html",
    "href": "analisis-datos.html",
    "title": "3  Análisis exploratorio",
    "section": "",
    "text": "“Exploratory data analysis can never be the whole story, but nothing else can serve as the foundation stone –as the first step.” — John Tukey\nMuchas veces se le llama análisis exploratorio a una combinación de resúmenes, gráficas y tablas cuyos propósitos pueden englobarse en:\nEsta fase del análisis de datos es fundamental, como la cita de Tukey explica arriba, y se caracteríza por un enfoque de detective: quizá tenemos algunas preguntas, algunas sospechas, y en esta fase acumulamos indicios que nos indiquen caminos prometedores de investigación.\nEn contraste, tenemos el análisis confirmatorio, que busca validar hipótesis o dar respuestas correctamente cuantificadas en cuanto a su incertidumbre o grado de error. En esta parte somos más jueces que detectives, y utilizamos más maquinaria matemática (teoría de probabilidad) para especificar con claridad nuestros supuestos y poder hacer cálculos cuidadosos, generalmente basados en algún tipo de aleatorización.\nNinguno de los dos tipos de análisis funciona muy bien sin el otro, (Tukey (1980)) y explicaremos por qué un poco más adelante. Por el momento, para ilustrar el enfoque exploratorio, comenzaremos con datos que podemos describir de manera completa y efectiva sin necesidad de hacer resúmenes o aplicar técnicas avanzadas."
  },
  {
    "objectID": "analisis-datos.html#ejemplo-nacimientos",
    "href": "analisis-datos.html#ejemplo-nacimientos",
    "title": "3  Análisis exploratorio",
    "section": "3.1 Ejemplo: nacimientos",
    "text": "3.1 Ejemplo: nacimientos\nConsideremos una parte de los datos de nacimientos por día del INEGI de 1999 a 2016. Consideraremos sólo tres meses: enero a marzo de 2016. Estos datos, por su tamaño, pueden representarse de manera razonablemente efectiva en una visualización de serie de tiempo. Examinamos partes del contenido de la tabla:\n\n\n\nExaminamos partes del contenido de la tabla:\n\ntab_1 <- nacimientos |> \n   select(fecha, n) |> \n   slice_head(n = 5)\ntab_2 <- nacimientos |> \n   select(fecha, n) |> \n   slice_tail(n = 5)\nkable(list(tab_1, tab_2)) |> kable_paper()\n\n\n\n\n  \n    \n\n\n \n  \n    fecha \n    n \n  \n \n\n  \n    2016-01-01 \n    3952 \n  \n  \n    2016-01-02 \n    4858 \n  \n  \n    2016-01-03 \n    4665 \n  \n  \n    2016-01-04 \n    5948 \n  \n  \n    2016-01-05 \n    6087 \n  \n\n\n\n \n    \n\n\n \n  \n    fecha \n    n \n  \n \n\n  \n    2016-03-27 \n    4112 \n  \n  \n    2016-03-28 \n    5805 \n  \n  \n    2016-03-29 \n    5957 \n  \n  \n    2016-03-30 \n    5766 \n  \n  \n    2016-03-31 \n    5497 \n  \n\n\n\n \n  \n\n\n\n\n\nEn un examen rápido de estos números no vemos nada fuera de orden. Los datos tienen forma de serie de tiempo regularmente espaciada (un dato para cada día). Podemos graficar de manera simple como sigue:\n\nggplot(nacimientos, aes(x = fecha, y = n)) +\n   geom_point() +\n   geom_line() + \n   scale_x_date(breaks = \"1 week\", date_labels = \"%d-%b\") \n\n\n\n\nEsta es una descripción de los datos, que quizá no es muy compacta pero muestra varios aspectos importantes. En este caso notamos algunos patrones que saltan a la vista. Podemos marcar los domingos de cada semana:\n\ndomingos_tbl <- nacimientos |> \n   filter(weekdays(fecha) == \"Sunday\")\nggplot(nacimientos, aes(x = fecha, y = n)) +\n   geom_vline(aes(xintercept = fecha), domingos_tbl, colour = \"salmon\") +\n   geom_point() +\n   geom_line() + \n   scale_x_date(breaks = \"1 week\", date_labels = \"%d-%b\") \n\n\n\n\nObservamos que los domingos ocurren menos nacimientos y los sábados también ocurren relativamente menos nacimentos. ¿Por qué crees que sea esto?\nAdicionalmente a estos patrones observamos otros aspectos interesantes:\n\nEl primero de enero hay considerablemente menos nacimientos de los que esperaríamos para un viernes. ¿Por qué?\nEl primero de marzo hay un exceso de nacimientos considerable. ¿Qué tiene de especial este primero de marzo?\n¿Cómo describirías lo que sucede en la semana que comienza el 21 de marzo? ¿Por qué crees que pase eso?\n¿Cuáles son los domingos con más nacimientos? ¿Qué tienen de especial y qué explicación puede tener?\n\nLa confirmación de estas hipótesis, dependiendo de su forma, puede ser relativamente simple (por ejemplo ver una serie más larga de domingos comparados con otros días de la semana) hasta muy compleja (investigar preferencias de madres, de doctores o de hospitales, costumbres y actitudes, procesos en el registro civil, etc.)"
  },
  {
    "objectID": "analisis-datos.html#procesos-generadores-de-datos",
    "href": "analisis-datos.html#procesos-generadores-de-datos",
    "title": "3  Análisis exploratorio",
    "section": "Procesos generadores de datos",
    "text": "Procesos generadores de datos\nDe este primer ejemplo donde usamos una gráfica simple, vemos que una visión descontextualizada de estos datos no tiene mucha utilidad\n\n\n\n\n\n\nEl proceso generador de datos\n\n\n\nNótese que en todas estas preguntas hemos tenido que recurrir a conocimientos generales y de dominio para interpretar y hacer hipótesis acerca de lo que vemos en la gráfica. Las explicaciones son típicamente complejas e intervienen distintos aspectos del comportamiento de actores, sistemas, y métodos de recolección de datos involucrados.\nAl conjunto de esos aspectos que determinan los datos que finalmente observamos le llamamos el proceso generador de datos.\n\n\nEl análisis de datos en general busca entender las partes importantes del proceso que los generó. En el análisis descriptivo y exploratorio buscamos iluminar ese proceso, proponer hipótesis y buscar caminos interesantes para investigar, ya sea con técnicas cuantitativas o con trabajo de campo (como sugiere el título de artículo de David A. Friedman: Statistical Models and Shoe Leather).\nCon la teoría de probabilidades podemos modelar más explícitamente partes de estos procesos generadores de datos, especialmente cuando controlamos parte de ese proceso generador mediante técnicas estadísticas de diseño, por ejemplo, usando aleatorización."
  },
  {
    "objectID": "analisis-datos.html#ejemplo-cálculos-renales",
    "href": "analisis-datos.html#ejemplo-cálculos-renales",
    "title": "3  Análisis exploratorio",
    "section": "Ejemplo (cálculos renales)",
    "text": "Ejemplo (cálculos renales)\nEn este ejemplo también intentaremos mostrar los datos completos sin intentar resumir.\nEste es un estudio real acerca de tratamientos para cálculos renales (Julious y Mullee (1994)). Pacientes se asignaron de una forma no controlada a dos tipos de tratamientos para reducir cálculos renales. Para cada paciente, conocemos el el tipo de ćalculos que tenía (grandes o chicos) y si el tratamiento tuvo éxito o no.\nLa tabla original se ve como sigue (muestreamos algunos renglones):\n\ncalculos <- read_csv(\"./datos/kidney_stone_data.csv\")\nnames(calculos) <- c(\"tratamiento\", \"tamaño\", \"éxito\")\ncalculos <- calculos |> \n   mutate(tamaño = ifelse(tamaño == \"large\", \"grandes\", \"chicos\")) |> \n   mutate(resultado = ifelse(éxito == 1, \"mejora\", \"sin_mejora\")) |> \n   select(tratamiento, tamaño, resultado)\nnrow(calculos)\n\n[1] 700\n\ncalculos |> sample_n(15) |> \n   kable() |> kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    tamaño \n    resultado \n  \n \n\n  \n    A \n    grandes \n    sin_mejora \n  \n  \n    A \n    grandes \n    mejora \n  \n  \n    B \n    grandes \n    sin_mejora \n  \n  \n    B \n    grandes \n    sin_mejora \n  \n  \n    B \n    chicos \n    mejora \n  \n  \n    A \n    grandes \n    sin_mejora \n  \n  \n    B \n    chicos \n    mejora \n  \n  \n    A \n    grandes \n    sin_mejora \n  \n  \n    B \n    chicos \n    mejora \n  \n  \n    B \n    chicos \n    sin_mejora \n  \n  \n    A \n    grandes \n    mejora \n  \n  \n    B \n    chicos \n    sin_mejora \n  \n  \n    B \n    chicos \n    mejora \n  \n  \n    A \n    grandes \n    mejora \n  \n  \n    B \n    chicos \n    sin_mejora \n  \n\n\n\n\n\nAunque estos datos contienen información de 700 pacientes (cada renglón es un paciente), los datos pueden resumirse sin pérdida de información contando como sigue:\n\ncalculos_agregada <- calculos |> \n   group_by(tratamiento, tamaño, resultado) |> \n   count()\ncalculos_agregada |> kable() |> kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    tamaño \n    resultado \n    n \n  \n \n\n  \n    A \n    chicos \n    mejora \n    81 \n  \n  \n    A \n    chicos \n    sin_mejora \n    6 \n  \n  \n    A \n    grandes \n    mejora \n    192 \n  \n  \n    A \n    grandes \n    sin_mejora \n    71 \n  \n  \n    B \n    chicos \n    mejora \n    234 \n  \n  \n    B \n    chicos \n    sin_mejora \n    36 \n  \n  \n    B \n    grandes \n    mejora \n    55 \n  \n  \n    B \n    grandes \n    sin_mejora \n    25 \n  \n\n\n\n\n\nEste resumen no es muy informativo, pero al menos vemos qué valores aparecen en cada columna de la tabla. Como en este caso nos interesa principalmente la tasa de éxito de cada tratamiento, podemos mejorar mostrando como sigue:\n\ncalculos_agregada |> pivot_wider(names_from = resultado, values_from = n) |> \n   mutate(total = mejora + sin_mejora) |> \n   mutate(prop_mejora = round(mejora / total, 2)) |> \n   select(tratamiento, tamaño, total, prop_mejora) |> \n   arrange(tamaño) |> \n   kable() |> kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    tamaño \n    total \n    prop_mejora \n  \n \n\n  \n    A \n    chicos \n    87 \n    0.93 \n  \n  \n    B \n    chicos \n    270 \n    0.87 \n  \n  \n    A \n    grandes \n    263 \n    0.73 \n  \n  \n    B \n    grandes \n    80 \n    0.69 \n  \n\n\n\n\n\nEsta tabla descriptiva es una reescritura de los datos, y no hemos resumido nada todavía. Sin embargo, esta tabla es apropiada para empezar a contestar la pregunta:\n\n¿Qué indican estos datos acerca de qué tratamiento es mejor? ¿Acerca del tamaño de cálculos grandes o chicos?\n\nSupongamos que otro analista decide comparar los pacientes que recibieron cada tratamiento, ignorando la variable de tamaño:\n\ncalculos |> group_by(tratamiento) |> \n   summarise(prop_mejora = mean(resultado == \"mejora\") |> round(2)) |> \n   kable() |> kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    prop_mejora \n  \n \n\n  \n    A \n    0.78 \n  \n  \n    B \n    0.83 \n  \n\n\n\n\n\ny parece ser que el tratamiento \\(B\\) es mejor que el \\(A\\). Esta es una paradoja (un ejemplo de la paradoja de Simpson) . Si un médico no sabe que tipo de cálculos tiene el paciente, ¿entonces debería recetar \\(B\\)? ¿Si sabe debería recetar \\(A\\)? Esta discusión parece no tener mucho sentido.\nPodemos investigar por qué está pasando esto considerando la siguiente tabla, que solo examina cómo se asignó el tratamiento dependiendo del tipo de cálculos de cada paciente:\n\ncalculos |> group_by(tratamiento, tamaño) |> count() |> \n   kable() |> kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    tamaño \n    n \n  \n \n\n  \n    A \n    chicos \n    87 \n  \n  \n    A \n    grandes \n    263 \n  \n  \n    B \n    chicos \n    270 \n  \n  \n    B \n    grandes \n    80 \n  \n\n\n\n\n\nNuestra hipótesis aquí es que la decisión de qué tratamiento usar depende del tamaño de los cálculos. En este caso, por alguna razón se prefiere utilizar el tratamiento \\(A\\) para cálculos grandes, y \\(B\\) para cálculos chicos. Esto quiere decir que en la tabla total el tratamiento \\(A\\) está en desventaja porque se usa en casos más difíciles, pero el tratamiento \\(A\\) parece ser en general mejor.\nIgual que en el ejemplo anterior, los resúmenes descriptivos están acompañados de hipótesis acerca del proceso generador de datos, y esto ilumina lo que estamos observando y nos guía hacia descripciones provechosas de los datos. Las explicaciones no son tan simples y, otra vez, interviene el comportamiento de doctores, tratamientos, y distintos tipos de padecimientos."
  },
  {
    "objectID": "analisis-datos.html#ejemplo",
    "href": "analisis-datos.html#ejemplo",
    "title": "3  Análisis exploratorio",
    "section": "Ejemplo",
    "text": "Ejemplo\nAhora supongamos que tenemos datos de un tratamiento para mejorar enfermedades de corazón. En el estudio también se mide, durante la duración del estudio, si la presión del paciente es alta o baja. Supongamos otra vez que tenemos dos tratamientos, A y B, y obtenemos los siguientes resultados:\n\ncorazon <- calculos |> rename(presión = tamaño) |> \n  mutate(presión = recode(presión, chicos = \"baja\", grandes = \"alta\"))\n\n\n\n\n\n \n  \n    tratamiento \n    presión \n    total \n    prop_mejora \n  \n \n\n  \n    A \n    alta \n    263 \n    0.73 \n  \n  \n    B \n    alta \n    80 \n    0.69 \n  \n  \n    A \n    baja \n    87 \n    0.93 \n  \n  \n    B \n    baja \n    270 \n    0.87 \n  \n\n\n\n\n\n\ncorazon |> group_by(tratamiento) |> \n   summarise(prop_mejora = mean(resultado == \"mejora\") |> round(2)) |> \n   kable() |> \n   kable_paper(full_width = FALSE)\n\n\n\n \n  \n    tratamiento \n    prop_mejora \n  \n \n\n  \n    A \n    0.78 \n  \n  \n    B \n    0.83 \n  \n\n\n\n\n\n\nEn este ejemplo, ¿cuál es el análisis más apropiado? ¿Qué cosas necesitarías saber para tomar una decisión?\n¿En qué es diferente o similar al caso de los cálculos renales?"
  },
  {
    "objectID": "analisis-datos.html#inferencia",
    "href": "analisis-datos.html#inferencia",
    "title": "3  Análisis exploratorio",
    "section": "3.2 Inferencia",
    "text": "3.2 Inferencia\nEn los ejemplos anteriores, sólo vimos muestras de datos (algunos pacientes, algunas fechas). Nuestras descripciones son, estrictamente hablando, válidas para esa muestra de los datos.\nSi quisiéramos generalizar a la población gneral de pacientes con cálculos (quizá en nuestra muestra el tratamiento A parece mejor, pero ¿qué podemos decir para la población de pacientes?), o quisiéramos predecir cómo van a ser los nacimientos en 2021, requerimos hacer inferencia. Este tipo de análisis, central en la estadística, busca establecer condiciones para poder generalizar de nuestra muestra a datos no observados (otros pacientes, nacimientos en el futuro), y cuantificar qué tan bien o mal podemos hacerlo.\nPara llegar a este tipo de análisis, generalmente tenemos que comenzar con el análisis exploratorio, y con la comprensión de los fundamentos del proceso generador asociado a nuestros datos. En algunos casos, veremos que es posible usar herramientas matemáticas para modelar aspectos de nuestro proceso generador de datos, que cuando son válidas, nos permiten generalizar y ampliar apropiadamente el rango de nuestras conclusiones.\nLa herramienta básica para construir, entender y operar con estos modelos es la teoría de probabilidad, que veremos más adelante."
  },
  {
    "objectID": "analisis-datos.html#ejemplo-más-de-nacimientos-en-méxico",
    "href": "analisis-datos.html#ejemplo-más-de-nacimientos-en-méxico",
    "title": "3  Análisis exploratorio",
    "section": "3.3 Ejemplo: más de nacimientos en México",
    "text": "3.3 Ejemplo: más de nacimientos en México\nEste ejemplo sigue sigue ideas de un análisis de A. Vehtari y A. Gelman, junto con análisis de serie de tiempo de Cleveland (1993)\nUsaremos los datos de nacimientos registrados por día en México, desde 1999. Haremos una pregunta como ¿cuáles son los cumpleaños más frecuentes?, o ¿Qué mes del año hay más nacimientos?\nUna gráfica popular (ver por ejemplo esta visualización):\n\n\n\n\n\n¿Cómo criticarías este análisis desde el punto de vista de los tres primeros principios del diseño analítico? ¿Las comparaciones son útiles? ¿Hay aspectos multivariados? ¿Qué tan bien explica o sugiere estructura, mecanismos o causalidad?\n\nDatos de natalidad para México\n\n\n\nConsideramos los datos agregados de número de nacimientos (registrados) por día desde 1999 hasta 2016.\nPodemos hacer una primera gráfica de la serie de tiempo que no es muy útil:\n\n\n\n\n\nHay varias características que notamos. Principalmente, la tendencia ligeramente decreciente de número de nacimientos a lo largo de los años, un patrón anual, dispersión producida por los días de la semana.\nSolo estas características hacen que la comparación entre días sea una difícil de interpretar. Supongamos que comparamos el número de nacimientos de dos miércoles dados. Esa comparación será diferente dependiendo del año donde ocurrieron, el mes donde ocurrieron, si semana santa ocurrió en algunos de los miércoles, y así sucesivamente.\nComo en nuestros ejemplos anteriores, la idea del siguiente análisis es aislar las componentes que observamos en la serie de tiempo: extraemos componentes ajustadas, y luego examinamos los residuales.\nEn este caso particular, construiremos una descomposición aditiva de la serie de tiempo (Cleveland (1993)).\n\n\nTendencia\nComenzamos por extraer la tendencia, haciendo promedios loess con vecindades relativamente grandes. Quizá preferiríamos suavizar menos para capturar más variación lenta, pero si hacemos esto en este punto empezamos a absorber parte de la componente anual:\n\nmod_1 <- loess(n ~ as.numeric(fecha), data = natalidad, span = 0.2, degree = 1)\ndatos_dia <- natalidad |> mutate(ajuste_1 = fitted(mod_1)) |> \n    mutate(res_1 = n - ajuste_1)\n\n\n\n\n\n\nA principios de 2000 el suavizador está en niveles de alrededor de 7000 nacimientos diarios, hacia 2015 ese número es más cercano a unos 6000.\n\n\nComponente anual\nRestamos a la serie la tendencia, y así obtenemos mejores comparaciones controlando por tendencia (por ejemplo, comparar un día de 2000 y de 2015 tendria más sentido). Ahora ajustamos los residuales del suavizado anterior, pero con menos suavizamiento. Así evitamos capturar tendencia:\n\nmod_anual <- loess(res_1 ~ as.numeric(fecha), data = datos_dia, degree = 2, span = 0.005)\ndatos_dia <- datos_dia |> mutate(ajuste_2 = fitted(mod_anual)) |> \n    mutate(res_2 = res_1 - ajuste_2)\n\n\n\n\n\n\n\n\nDía de la semana\nAhora podemos capturar el efecto de día de la semana. En este caso, podemos hacer suavizamiento loess para cada serie independiente\n\ndatos_dia <- datos_dia |> group_by(dia_semana) |> nest() |> \n    mutate(ajuste_mod = \n      map(data, ~ loess(res_2 ~ as.numeric(fecha), data = .x, span = 0.1, degree = 1))) |> \n    mutate(ajuste_3 =  map(ajuste_mod, fitted)) |> \n    select(-ajuste_mod) |> unnest(cols = c(data, ajuste_3)) |> \n    mutate(res_3 = res_2 - ajuste_3) |> ungroup()\n\n\n\n\n\n\n\n\nResiduales\nExaminamos los residuales finales quitando los efectos ajustados:\n\nggplot(datos_dia, aes(x = fecha, y = res_3)) + geom_line() +\n    geom_smooth(method = \"loess\", span = 0.02, \n                method.args = list(degree=1, family = \"symmetric\"))\n\n`geom_smooth()` using formula 'y ~ x'\n\n\n\n\n\nObservación: nótese que la distribución de estos residuales tiene irregularidades interesante: es una distribución con colas largas, y no se debe a unos cuantos atípicos. Esto generalmente es indicación que hay factores importantes que hay que examinar en los residuales:\n\n\n\n\n\n\n\nReestimación\nCuando hacemos este proceso secuencial ajuste -> residual, a veces conviene iterarlo. La razón es que un una segunda o tercera pasada podemos hacer mejores estimaciones de cada componente, y es posible suavizar menos sin capturar componentes de más alta frecuencia.\nAsí que podemos regresar a la serie original para hacer mejores estimaciones, más suavizadas:\n\n# quitamos componente anual y efecto de día de la semana\ndatos_dia <- datos_dia |> mutate(n_1 = n - ajuste_2 - ajuste_3)\n# reajustamos\nmod_1 <- loess(n_1 ~ as.numeric(fecha), data = datos_dia, span = 0.02, degree = 2,\n               family = \"symmetric\")\n\n\n\n\n\n\n\nmod_anual <- loess(n_2 ~ as.numeric(fecha), data = datos_dia, \n               degree = 2,  span = 0.01, family = \"symmetric\")\ndatos_dia <- datos_dia |>\n    mutate(ajuste_5 = fitted(mod_anual)) |> \n    mutate(res_5 = n_2 - ajuste_5) |>\n    mutate(n_3 = n - ajuste_4 - ajuste_5)\n\n\n\n\n\n\nY ahora repetimos con la componente de día de la semana:\n\n\n\n\n\n\n\nAnálisis de componentes\nAhora comparamos las componentes estimadas y los residuales en una misma gráfica. La suma de todas estas componentes da los datos originales: es una descomposición aditiva.\n\n\n\n\n\nY esto nos da muchas comparaciones buenas que explican la variación que vimos en los datos. Una gran parte de los residuales está entre +-/250 nacimientos por día, pero las colas tienen una dispersión mucho mayor:\n\nquantile(datos_dia$res_6, c(00, .01,0.05, 0.10, 0.90, 0.95, 0.99, 1)) |> round()\n\n   0%    1%    5%   10%   90%   95%   99%  100% \n-2238 -1134  -315  -202   188   268   516  2521 \n\n\n¿A qué se deben estas colas tan largas?\n\n\n\n\n\nViernes 13?\nPodemos empezar con una curosidad: En Viernes o Martes 13, ¿nacen menos niños?\n\n\n\n\n\nNótese que fue útil agregar el indicador de Semana santa por el Viernes 13 de Semana Santa que se ve como un atípico en el panel de los viernes 13.\n\n\nResiduales: antes y después de 2006\nVeamos primero una agregación sobre los años de los residuales. Lo primero es observar un cambio que sucedió repentinamente en 2006:\n\nsept_1 <- ymd(paste0(2000:2016, \"-09-01\")) |> yday()\ndatos_dia <- datos_dia |> mutate(antes_2006 = ifelse(año < 2006, \"Antes de 2006\", \"2006 en adelante\"))\nggplot(datos_dia , aes(x = dia_año, y = res_6, group = factor(año))) + \n    geom_point(size = 0.5) +\n    geom_vline(xintercept = sept_1, alpha = 0.3, colour = \"red\") +\n    facet_wrap( ~ antes_2006, ncol = 1) + ylab(\"Residual: exceso de nacimientos\") +\n    annotate(\"text\", x = 260, y = -1500, label = \"Sept 1\", colour = \"red\")\n\n\n\n\nLa razón es un cambio en la ley acerca de cuándo pueden entrar los niños a la primaria. Antes era por edad y había poco margen. Ese exceso de nacimientos son reportes falsos para que los niños no tuvieran que esperar un año completo por haber nacido unos cuantos días antes de la fecha límite.\nOtras características que debemos investigar:\n\nEfectos de Año Nuevo, Navidad, Septiembre 16 y otros días feriados como Febrero 14.\nSemana santa: como la fecha cambia, vemos que los residuales negativos tienden a ocurrir dispersos alrededor del día 100 del año.\n\n\n\nOtros días especiales: más de residuales\nAhora promediamos residuales (es posible agregar barras para indicar dispersión a lo largo de los años) para cada día del año. Podemos identificar ahora los residuales más grandes: se deben, por ejemplo, a días feriados, con consecuencias adicionales que tienen en días ajuntos (excesos de nacimientos):\n\n\n`summarise()` has grouped output by 'dia_año_366', 'antes_2006'. You can\noverride using the `.groups` argument.\n\n\n\n\n\n\n\nSemana santa\nPara Semana Santa tenemos que hacer unos cálculos. Si alineamos los datos por días antes de Domingo de Pascua, obtenemos un patrón de caída fuerte de nacimientos el Viernes de Semana Santa, y la característica forma de “valle con hombros” en días anteriores y posteriores estos Viernes. ¿Por qué ocurre este patrón?\n\n\n`geom_smooth()` using formula 'y ~ x'\n\n\n\n\n\nNótese un defecto de nuestro modelo: el patrón de “hombros” alrededor del Viernes Santo no es suficientemente fuerte para equilibrar los nacimientos faltantes. ¿Cómo podríamos mejorar nuestra descomposición?"
  },
  {
    "objectID": "analisis-datos.html#descripciones-simples-y-problemas-complejos",
    "href": "analisis-datos.html#descripciones-simples-y-problemas-complejos",
    "title": "3  Análisis exploratorio",
    "section": "3.4 Descripciones simples y problemas complejos",
    "text": "3.4 Descripciones simples y problemas complejos\nMuchas veces se descarta al análisis descriptivo o exploratorio (al menos en sus formas más crudas) como algo que no requiere mucha habilidad técnica o conocimiento de dominio, o cuando se quiere evitar plantear hipótesis claras acerca de los datos que ayuden en su entendimiento.\nEn realidad el análisis descriptivo y exploratorio es crucial en el análisis de datos en general, y tiene siempre que venir acompañado de conocimiento de dominio, habilidad técnica, una mente crítica y muchas veces ingenio y creatividad."
  },
  {
    "objectID": "analisis-datos.html#qué-preguntas-formular",
    "href": "analisis-datos.html#qué-preguntas-formular",
    "title": "3  Análisis exploratorio",
    "section": "3.5 ¿Qué preguntas formular?",
    "text": "3.5 ¿Qué preguntas formular?\nExisten algunas prácticas generales que utilizamos para hacer validaciones y resúmenes simples de los datos que discutiremos más adelante. Por el momento, discutimos las razones por las que estamos haciendo ese análisis en un principio.\nEn general, comenzamos con algunas preguntas básicas que quisiéramos contestar con los datos. El análisis exploratorio juega un papel central para comenzar a responder:\n\n¿Es razonable la pregunta que queremos contestar?\n¿Podemos contestar la pregunta con los datos que tenemos?\n\nAunque estos dos incisos a veces parecen transparentes y simples de contestar, generalmente no lo son: las preguntas que queremos contestar y los problemas que queremos resolver usualmente son no triviales."
  },
  {
    "objectID": "analisis-datos.html#formulación-de-preguntas-y-respuestas",
    "href": "analisis-datos.html#formulación-de-preguntas-y-respuestas",
    "title": "3  Análisis exploratorio",
    "section": "3.6 Formulación de preguntas y respuestas",
    "text": "3.6 Formulación de preguntas y respuestas\nEl proceso de la ciencia de datos no va desde las preguntas hasta las respuestas en un camino lineal.\nEn esta gráfica Roger Peng hay tres caminos: uno es uno ideal que pocas veces sucede, otro produce respuestas poco útiles pero es fácil, y otro es tortuoso pero que caracteriza el mejor trabajo de análisis de datos:\n\n\n\n\n\nAdaptado de R. Peng: Tukey, design thinking and better questions\n\n\n\n\nEl proceso típico involucra pasos como los siguientes, y es un proceso no lineal:\n\nHacer preguntas de la materia que nos interesa\nRecolectar, consumir y procesar los datos para abordarla\nExplorar estos datos y evaluar su calidad\nHacer análisis o modelos\nReportar los resultados de forma adecuada y con esto resolver y replantear las preguntas importantes.\n\nPor ejemplo, evaluar la calidad de los datos puede llevar a replantear la necesidad de obtener más información o de hacer estudios específicos. Así también, los modelos pueden dar luz sobre las preguntas que los originan.\n\n\n\n¿Por dónde empezar el análisis descriptivo y exploratorio? ¿Cómo sabemos que vamos por buen camino y qué hacer cuando sentimos que nos estancamos?"
  },
  {
    "objectID": "analisis-datos.html#cómo-saber-que-vamos-en-el-camino-correcto",
    "href": "analisis-datos.html#cómo-saber-que-vamos-en-el-camino-correcto",
    "title": "3  Análisis exploratorio",
    "section": "3.7 ¿Cómo saber que vamos en el camino correcto?",
    "text": "3.7 ¿Cómo saber que vamos en el camino correcto?\nComenzamos por discribir cuáles son los signos de calidad del análisis que piensa usarse como insumo para una decisión. Los principios del diseño analítico de Edward Tufte (Tufte (2006)) son:\nLos análisis exitosos:\n\nMuestran y explotan comparaciones, diferencias y variación.\nTienden a ser multivariados: estudian conjuntamente más de 1 o 2 variables.\nMuestran y explotan estructura sistemática, sugieren explicaciones. Cuando es posible, aportan evidencia de causalidad.\n\nTambién muy importantes pero en los que pondremos menos énfasis:\n\nDatos y procesos están bien documentados. El análisis es reproducible y transparente.\nIntentan integrar la evidencia completa: teoría, texto, explicaciones, tablas y gráficas.\n\nY finalmente, el principio general:\n\nLa calidad, relevancia, e integridad del contenido y los datos son los que al final sostienen al análisis - por sí mismos, el uso de técnicas sofisticadas, algoritmos novedosos, uso o no de grandes datos, estilo de visualizaciones o presentaciones no son marcas o sellos de un análisis de datos exitoso.\n\n\n\n\n\n\n\nTip\n\n\n\nEvaluar un análisis o resultado en estos seis puntos generalmente ayuda en el proceso de refinamiento de preguntas y respuestas."
  },
  {
    "objectID": "analisis-datos.html#gráfica-de-minard",
    "href": "analisis-datos.html#gráfica-de-minard",
    "title": "3  Análisis exploratorio",
    "section": "3.8 Gráfica de Minard",
    "text": "3.8 Gráfica de Minard\nLa ilustración que Tufte usa para mostrar excelencia en diseño analítico es una gráfica de Minard que sirve para entender la campaña de Napoleón (1812) en Rusia. Es un ejemplo atípico, pero representa bien los principios y también muestra la importancia del ingenio en la construcción de un anállsis:\n\n\n\n\n\nMarcha de Napoleón de Charles Minard. Tomado de Wikipedia\n\n\n\n\n\n\n\n¿Cómo satisface los principios del diseño analítico este gráfico?\n\n\n\n\n\n\nCleveland, William S. 1993. Visualizing Data. Hobart Press.\n\n\nJulious, Steven A, y Mark A Mullee. 1994. «Confounding and Simpson’s paradox». BMJ 309 (6967): 1480-81. https://doi.org/10.1136/bmj.309.6967.1480.\n\n\nTufte, Edward R. 2006. Beautiful Evidence. Cheshire, CT: Graphics Press.\n\n\nTukey, John W. 1980. «We Need Both Exploratory and Confirmatory». The American Statistician 34 (1): 23-25. http://www.jstor.org/stable/2682991."
  },
  {
    "objectID": "inferencia.html",
    "href": "inferencia.html",
    "title": "4  Inferencia estadística",
    "section": "",
    "text": "Nos concentraremos en dos de las situaciones más comunes:\n\nInferencia a poblaciones: el proceso generador de datos “selecciona” a algunos elementos de una población, y queremos decir algo acerca de la población completa.\n\nPor ejemplo, consideremos esta población de 15 personas:\n\n\n\n\n\n\n  \n  \n    \n      id\n      edad\n      estatura\n      peso\n    \n  \n  \n    1\n61\n1.58\n60\n    2\n24\n1.72\n72\n    3\n43\n1.64\n56\n    4\n32\n1.50\n60\n    5\n55\nNA\nNA\n    6\n39\nNA\nNA\n    7\n27\nNA\nNA\n    8\n44\nNA\nNA\n    9\n56\nNA\nNA\n    10\n54\nNA\nNA\n    11\n33\nNA\nNA\n    12\n25\nNA\nNA\n    13\n30\nNA\nNA\n    14\n19\nNA\nNA\n    15\n60\nNA\nNA\n  \n  \n  \n\n\n\n\nPara una muestra de ellos tenemos información acerca de su estatura y peso. ¿Qué podríamos decir acerca de la estatura y el peso de la población general?\n\nInferencia causal: el proceso generador “asigna” tratamientos a una población o parte de ella, y quisiéramos saber cómo se comportarían las unidades tratadas si no recibieran tratamiento, y también cómo se comportarían unidades no tratadas si recibieran el tratamiento.\n\nEn este caso, la situación se ve como sigue. Imaginemos que tenemos 15 personas con dolor de cabeza, y obtenemos los siguientes datos:\n\n\n\n\n\n\n  \n  \n    \n      id\n      edad\n      dolor_con_aspirina\n      dolor_sin_aspirina\n      tomo_aspirina\n      dolor\n    \n  \n  \n    1\n37\n6\nNA\n1\n6\n    2\n31\n6\nNA\n1\n6\n    3\n51\nNA\n3\n0\n3\n    4\n18\n6\nNA\n1\n6\n    5\n45\n6\nNA\n1\n6\n    6\n23\nNA\n3\n0\n3\n    7\n20\nNA\n3\n0\n3\n    8\n40\n6\nNA\n1\n6\n    9\n30\nNA\n3\n0\n3\n    10\n44\n6\nNA\n1\n6\n    11\n61\nNA\n3\n0\n3\n    12\n62\nNA\n3\n0\n3\n    13\n60\n6\nNA\n1\n6\n    14\n27\nNA\n3\n0\n3\n    15\n42\n6\nNA\n1\n6\n  \n  \n  \n\n\n\n\nNuestra pregunta en este caso es del tipo: ¿ayuda la aspirina a reducir el dolor de cabeza en esta población? ¿qué tanto ayuda? Igualmente, tenemos información incompleta, en el sentido de que sólo observamos un resultado potencial de cada persona, dependiendo de si tomó aspirina o no. Si supiéramos los dos resultados potenciales de cada persona entonces podríamos contestar la pregunta sin dificultad.\n\n\n\n\n\n\nDatos incompletos e incertidumbre\n\n\n\nCasi por regla general, el hecho de que tengamos datos incompletos implica que una respuesta apropiada a la pregunta incorporará cierto grado de incertidumbre, y por lo tanto conviene utilizar modelos de probabilidad para describir esa incertidumbre.\nEn algunos casos, sin embargo, si controlamos algunas partes del proceso generador de datos, entonces es posible simplificar mucho el análisis, incluso al punto de que los modelos tienen menos relevancia."
  },
  {
    "objectID": "pruebas-hipotesis.html",
    "href": "pruebas-hipotesis.html",
    "title": "5  Pruebas de hipótesis",
    "section": "",
    "text": "Las primeras técnicas que veremos intentan contestar la siguiente pregunta:\nPor ejemplo:\nO también:"
  },
  {
    "objectID": "pruebas-hipotesis.html#comparación-con-poblaciones-de-referencia",
    "href": "pruebas-hipotesis.html#comparación-con-poblaciones-de-referencia",
    "title": "5  Pruebas de hipótesis",
    "section": "Comparación con poblaciones de referencia",
    "text": "Comparación con poblaciones de referencia\nEn las prueba de hipótesis, tratamos de construir distribuciones de referencia para comparar resultados que obtengamos con un “estándar” de variación, y juzgar si nuestros resultados son consistentes con la referencia o no (1).\nEn algunos casos, ese estándar de variación puede construirse con datos históricos.\n\nEjemplo\nSupongamos que estamos considerando cambios rápidos en una serie de tiempo de alta frecuencia. Hemos observado la serie en su estado “normal” durante un tiempo considerable, y cuando observamos nuevos datos quisiéramos juzgar si hay indicaciones o evidencia en contra de que el sistema sigue funcionando de manera similar.\nDigamos que monitoreamos ventanas de tiempo de tamaño 20 y necesitamos tomar una decisión. Abajo mostramos cinco ejemplos donde el sistema opera normalmente, que muestra la variabilidad en el tiempo en ventanas cortas del sistema.\nAhora suponemos que obtenemos una nueva ventana de datos. ¿Hay evidencia en contra de que el sistema sigue funcionando de manera similar?\nNuestra primera inclinación debe ser comparar: en este caso, compararamos ventanas históricas con nuestra nueva serie:\n\n\n\n\n# usamos datos simulados para este ejemplo\nset.seed(8812)\nhistoricos <- simular_serie(2000)\n\n\n\n\n\n\n¿Vemos algo diferente en los datos nuevos (el panel de color diferente)?\nIndendientemente de la respuesta, vemos que hacer este análisis de manera tan simple no es siempre útil: seguramente podemos encontrar maneras en que la nueva muestra (4) es diferente a muestras históricas. Por ejemplo, ninguna de muestras tiene un “forma de montaña” tan clara.\nNos preguntamos si no estamos sobreinterpretando variaciones que son parte normal del proceso.\nPodemos hacer un mejor análisis si extraemos varias muestras del comportamiento usual del sistema, graficamos junto a la nueva muestra, y revolvemos las gráficas para que no sepamos cuál es cuál. Entonces la pregunta es:\n\n¿Podemos detectar donde están los datos nuevos?\n\nEsta se llama una prueba de lineup, o una prueba de ronda de sospechosos (Hadley Wickham et al. (2010)). En la siguiente gráfica, en uno de los páneles están los datos recientemente observados. ¿Hay algo en los datos que distinga al patrón nuevo?\n\n\n\n\n\nEjercicio: ¿cuáles son los datos nuevos (solo hay un panel con los nuevos datos)? ¿Qué implica que la gráfica que escogamos como “más diferente” no sean los datos nuevos? ¿Qué implica que le “atinemos” a la gráfica de los datos nuevos?\nAhora observamos al sistema en otro momento y repetimos la comparación. En el siguiente caso obtenemos:\n\n\n\n\n\nAunque es imposible estar seguros de que ha ocurrido un cambio, la diferencia de una de las series es muy considerable. Si identificamos los datos correctos, la probabilidad de que hayamos señalado la nueva serie “sobreinterpretando” fluctuaciones en un proceso que sigue comportándose normalente es 0.05 - relativamente baja. Detectar los datos diferentes es evidencia en contra de que el sistema sigue funcionando de la misma manera que antes.\n\n\n\n\n\n\nPruebas de hipótesis\n\n\n\n\nLlamamos hipótesis nula a la hipótesis de que los nuevos datos son producidos bajo las mismas condiciones que los datos de control o de referencia.\nSi no escogemos la gráfica de los nuevos datos, nuestra conclusión es que la prueba no aporta evidencia en contra de la hipótesis nula.\nSi escogemos la gráfica correcta, nuestra conclusión es que la prueba aporta evidencia en contra de la hipótesis nula.\n\n¿Qué tan fuerte es la evidencia, en caso de que descubrimos los datos no nulos?\n\nCuando el número de paneles es más grande y detectamos los datos, la evidencia es más alta en contra de la nula. Decimos que el nivel de significancia de la prueba es la probabilidad de seleccionar a los datos correctos cuando la hipótesis nula es cierta (el sistema no ha cambiado).\n\n\n\nEn el caso de 20 paneles, la significancia es de 1/20 = 0.05. Cuando detectamos los datos nuevos, niveles de significancia más bajos implican más evidencia en contra de la nula.\nAdicionalmente, si acertamos, y la diferencia es más notoria y fue muy fácil detectar la gráfica diferente (pues sus diferencias son más extremas), esto también sugiere más evidencia en contra de la hipótesis nula (esto tiene qué ver con el valor p que veremos más adelante.)\nEsta prueba rara vez (o nunca) nos da seguridad completa acerca de ninguna conclusión, aún cuando hiciéramos muchos páneles."
  },
  {
    "objectID": "pruebas-hipotesis.html#cuantificando-la-distribución-de-referencia",
    "href": "pruebas-hipotesis.html#cuantificando-la-distribución-de-referencia",
    "title": "5  Pruebas de hipótesis",
    "section": "5.1 Cuantificando la distribución de referencia",
    "text": "5.1 Cuantificando la distribución de referencia\nEn el ejemplo anterior estamos intentando dectectar cualquier desviación del comportamiento normal del sistema de una manera rigurosa. Podemos hacerlo más cuantitativo creando estadísticas resumen de las series. Por ejemplo, podríamos utilizar la variabilidad que tienen las series alrededor de su nivel general.\n\nsd_simple <- function(x){\n  mod <- HoltWinters(x, beta=FALSE, gamma=FALSE)\n  suavizamiento <- fitted(mod)[,1] |> as.numeric()\n  sd(x[-1] - suavizamiento)\n}\nreferencia_tbl <- muestrear_ventanas(historicos, n_ventana = 1000) |> \n  pluck(\"lineup\") |> \n  group_by(rep) |> \n  summarise(est_prueba = sd_simple(obs))\nreferencia_tbl |> head()\n\n# A tibble: 6 × 2\n    rep est_prueba\n  <int>      <dbl>\n1     1      0.803\n2     2      1.95 \n3     3      1.10 \n4     4      1.19 \n5     5      0.791\n6     6      2.42 \n\n\n\nggplot(referencia_tbl, aes(x = est_prueba)) + \n  geom_histogram() +\n  geom_vline(xintercept = sd_simple(observados$obs), colour = \"red\") +\n  annotate(\"text\", x = 2.5, y = 30, \n     label = \"diferencia observada\", colour = \"red\", angle = 90)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nY confirmamos que en efecto el valor observado (línea roja) es uno muy extremo, y poco consistente con el comportamiento usual del sistema."
  },
  {
    "objectID": "pruebas-hipotesis.html#aleatorización-y-permutaciones",
    "href": "pruebas-hipotesis.html#aleatorización-y-permutaciones",
    "title": "5  Pruebas de hipótesis",
    "section": "5.2 Aleatorización y permutaciones",
    "text": "5.2 Aleatorización y permutaciones\nMuchas veces no tenemos datos históricos relevantes para construir una referencia (una distribución bajo la hipótesis nula) que nos permita evaluar si los nuevos datos muestran comportamiento no usual.\nSin embargo, si controlamos el proceso generador de datos introduciendo aleatorización, es posible construir una distribución de referencia con los datos observados.\n\nSupongamos que jardinero amateur quiere decidir qué fertilizante usar: el usual \\(A\\) o uno nuevo \\(B\\). El resultado que le interesa es el rendimiento de cada planta (cuantos kilos de jitomates produjo cada planta). El jardinero tiene 11 plantas, que estan en una línea. Quiere decidir si debería cambiar al nuevo fertilizante \\(B\\) o quedarse con el anterior.\n\nEl jardinero intuye que quizá no es buena idea poner en las primeras 5 plantas \\(A\\) y luego en las últimas 6 \\(B\\). La razón es que posiciones a lo largo de su hilera pueden recibir cantidades distintas de sol, de humedad, de nutrientes,e tc.\nDecide entonces distribuir al azar los tratamientos (5 de tipo A y 5 de tipo B). Obtiene los siguientes resultados:\n\nres_obs <- tibble(planta = 1:11,\n       T = c(\"a\", \"a\", \"b\", \"b\", \"a\", \"b\", \"b\", \"b\", \"a\", \"a\", \"b\"),\n       y = c(29.9, 11.4, 26.6, 23.7, 25.3, 28.5, 14.2, 17.9, 16.5, 21.1, 24.3) / 2)\nres_obs |> arrange(T) |> kable() |> kable_paper()\n\n\n\n \n  \n    planta \n    T \n    y \n  \n \n\n  \n    1 \n    a \n    14.95 \n  \n  \n    2 \n    a \n    5.70 \n  \n  \n    5 \n    a \n    12.65 \n  \n  \n    9 \n    a \n    8.25 \n  \n  \n    10 \n    a \n    10.55 \n  \n  \n    3 \n    b \n    13.30 \n  \n  \n    4 \n    b \n    11.85 \n  \n  \n    6 \n    b \n    14.25 \n  \n  \n    7 \n    b \n    7.10 \n  \n  \n    8 \n    b \n    8.95 \n  \n  \n    11 \n    b \n    12.15 \n  \n\n\n\n\n\nComo resumen, puede utilizar la diferencia de medias entre los dos tratamientos:\n\ndif_obs <- res_obs |> group_by(T) |> \n  summarise(media = mean(y)) |> \n  pivot_wider(names_from = T, values_from = media) |> \n  mutate(diferencia = round(b - a, 3))\ndif_obs\n\n# A tibble: 1 × 3\n      a     b diferencia\n  <dbl> <dbl>      <dbl>\n1  10.4  11.3      0.847\n\n\nY vemos que \\(B\\) tuvo mejores resultados con esta estadística de prueba. Sin embargo, este experimento tiene varias fuentes de variación, y no tenemos una distribución de referencia para comparar que nos diga cuánta variación esperamos en este tipo de experimentos.\nLa idea original de Fisher fue la siguiente:\n\nNuestra hipótesis nula es que los tratamientos a y b son iguales (es decir, si en los casos donde usamos b hubiéramos usado a hubiéramos obtenido los mismos resultados, y viceversa).\nEsto implica que las etiquetas a y b no tienen significado, podríamos permutarlas y hubiéramos obtenido los mismos resultados.\nPodemos ver entonces cuánta variación existe en la diferencia de promedios bajo el supuesto de la hipótesis nula, y el hecho de que distribuimos al azar el tratamiento: esto podemos hacerlo permutando las etiquetas del tratamiento en la tabla que obtuvimos y calculando los promedios correspondientes.\n\n\ncalc_permutacion <- function(datos_tbl, tratamiento){\n  # permutar\n  datos_perm_tbl <- datos_tbl |> \n    mutate({{ tratamiento }} := sample({{ tratamiento }}))\n  # calcular estadística\n  datos_perm_tbl |> group_by({{ tratamiento }}) |> \n    summarise(media = mean(y)) |> \n    pivot_wider(names_from = {{ tratamiento }}, values_from = media) |> \n    mutate(diferencia = round(b - a, 3))\n}\n\nPor ejemplo:\n\ncalc_permutacion(res_obs, T)\n\n# A tibble: 1 × 3\n      a     b diferencia\n  <dbl> <dbl>      <dbl>\n1  10.4  11.3      0.975\n\n\nY ahora podemos repetir un número grande de veces:\n\nreferencia_tbl <- map_df(1:2000, function(rep){\n  calc_permutacion(res_obs, T) |> mutate(rep = rep)\n})\nreferencia_tbl |> head() |> kable() |> \n  kable_paper(full_width = FALSE)\n\n\n\n \n  \n    a \n    b \n    diferencia \n    rep \n  \n \n\n  \n    12.07 \n    9.891667 \n    -2.178 \n    1 \n  \n  \n    11.89 \n    10.041667 \n    -1.848 \n    2 \n  \n  \n    10.19 \n    11.458333 \n    1.268 \n    3 \n  \n  \n    11.01 \n    10.775000 \n    -0.235 \n    4 \n  \n  \n    9.71 \n    11.858333 \n    2.148 \n    5 \n  \n  \n    9.86 \n    11.733333 \n    1.873 \n    6 \n  \n\n\n\n\n\nY hacemos lo mismo que hicimos en el ejemplo anterior:\n\nggplot(referencia_tbl, aes(x = diferencia)) +\n  geom_histogram() + \n  geom_vline(data = dif_obs, aes(xintercept = diferencia),\n             colour = \"red\") +\n    annotate(\"text\", x = 1, y = 30, \n     label = \"diferencia observada\", colour = \"red\", angle = 90)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nEn este caso, vemos que nuestra observación es consistente como proveniente de la distribución de referencia (construida con permutaciones).\nLa diferencia que observamos es consistente con la variabilidad en nuestra estadística de prueba bajo distintas aleatorizaciones si los tratamientos a y b son equivalentes. Nuestra conclusión es que no tenemos evidencia para preferir b sobre a.\n\ndiferencia_obs <- dif_obs$diferencia\nreferencia_tbl |> \n  mutate(mejor_que_observado = diferencia > diferencia_obs) |> \n  summarise(valor_p = mean(mejor_que_observado))\n\n# A tibble: 1 × 1\n  valor_p\n    <dbl>\n1    0.33\n\n\nBajo el supuesto de equivalencia de tratamientos, la probabilidad de observar un resultado mejor del que observamos es más de 1/3."
  },
  {
    "objectID": "pruebas-hipotesis.html#comparando-distribuciones",
    "href": "pruebas-hipotesis.html#comparando-distribuciones",
    "title": "5  Pruebas de hipótesis",
    "section": "Comparando distribuciones",
    "text": "Comparando distribuciones\nAhora intentamos un ejemplo más típico.\nSupongamos tenemos muestras para tres grupos a, b y c, que quiere decir que dentro de cada grupo, el proceso e selección de los elementos se hace de manera al azar y de manera simétrica (por ejemplo cada elemento tiene a misma probabiidad de ser seleccionado, y las extracciones se hacen de manera independiente.)\nQueremos comparar las distribuciones de los datos obtenidos para cada grupo. Quizá la pregunta detrás de esta comparación es: el grupo de clientes b recibió una promoción especial. ¿Están gastando más? La medición que comparamos es el gasto de los clientes.\n\n\n\n\n\nEn la muestra observamos diferencias entre los grupos. Pero notamos adicionalmente que hay mucha variación dentro de cada grupo. Nos podríamos preguntar entonces si las diferencias que observamos se deben variación muestral, por ejemplo.\nPodemos construir ahora una hipótesis nula, que establece que las observaciones provienen de una población similar:\n\nLas tres poblaciones (a, b, c) son prácticamente indistiguibles. En este caso, la variación que observamos se debería a que tenemos información incompleta.\n\nComo en el ejemplo anterior necesitamos construir o obtener una distribución de referencia para comparar qué tan extremos o diferentes son los datos que observamos. Esa distribución de referencia debería estar basada en el supuesto de que los grupos producen datos de distribuciones similares.\nSi tuvieramos mediciones similares históricas de estos tres grupos, quizá podríamos extraer datos de referencia y comparar, como hicimos en el ejempo anterior. Pero esto es menos común en este tipo de ejemplos."
  },
  {
    "objectID": "pruebas-hipotesis.html#permutaciones-y-el-lineup",
    "href": "pruebas-hipotesis.html#permutaciones-y-el-lineup",
    "title": "5  Pruebas de hipótesis",
    "section": "Permutaciones y el lineup",
    "text": "Permutaciones y el lineup\nPara abordar este problema podemos pensar en usar permutaciones de los grupos de la siguiente forma (1, Hesterberg (2015)):\n\nSi los grupos producen datos bajo procesos idénticos, entonces los grupos a, b, c solo son etiquetas que no contienen información.\nPodríamos permutar al azar las etiquetas y observar nuevamente la gráfica de caja y brazos por grupos.\nSi la hipótesis nula es cierta (grupos idénticos), esta es una muestra tan verosímil como la que obtuvimos.\nAsí que podemos construir datos de referencia permutando las etiquetas de los grupos al azar, y observando la variación que ocurre.\nSi la hipótesis nula es cercana a ser cierta, no deberíamos de poder distinguir fácilmente los datos observados de los producidos con las permutaciones al azar.\n\nVamos a intentar esto, por ejemplo usando una gráfica de cuantiles simplificada. Hacemos un lineup, o una rueda de sospechosos (usamos el paquete H. Wickham, Chowdhury, y Cook (2012), ver Hadley Wickham et al. (2010)), donde 19 de los acusados son generados mediante permutaciones al azar de la variable del grupo, y el culpable (los verdaderos datos) están en una posición escogida al azar. ¿Podemos identificar los datos verdaderos? Para evitar sesgarnos, también ocultamos la etiqueta verdadera\nUsamos una gráfica que muestra los cuantes 0.10, 0.50, 0.90:\n\nset.seed(88)\nreps <- lineup(null_permute(\"grupo\"), muestra_tab, n = 20)\n\ndecrypt(\"pPrt Zh4h Bk VyJB4Byk ub\")\n\nreps_mezcla <- reps |>  mutate(grupo_1 = factor(digest::digest2int(grupo) %% 177))\ngrafica_cuantiles(reps_mezcla, grupo_1, x) + \n    facet_wrap(~.sample, ncol = 5) + ylab(\"x\") + \n    labs(caption = \"Mediana y percentiles 10% y 90%\")+ geom_point(aes(colour = grupo_1))\n\n`summarise()` has grouped output by 'grupo_1'. You can override using the\n`.groups` argument.\n\n\n\n\n\nY la pregunta que hacemos es podemos distinguir nuestra muestra entre todas las replicaciones producidas con permutaciones?\nEjercicio: ¿dónde están los datos observados? Según tu elección, ¿qué tan diferentes son los datos observados de los datos nulos?\nEn este ejemplo, es difícil indicar cuáles son los datos. Los grupos tienen distribuciones similares y es factible que las diferencias que observamos se deban a variación muestral.\n\nSi la persona escoge los verdaderos datos, encontramos evidencia en contra de la hipótesis nula (los tres grupos son equivalentes). En algunos contextos, se dice que los datos son significativamente diferentes al nivel 0.05. Esto es evidencia en contra de que los datos se producen de manera homogénea, independientemente del grupo.\nSi la persona escoge uno de los datos permutados, no encontramos evidencia en contra de que los tres grupos producen datos con distribuciones similares."
  },
  {
    "objectID": "pruebas-hipotesis.html#comparaciones-con-lineup-2",
    "href": "pruebas-hipotesis.html#comparaciones-con-lineup-2",
    "title": "5  Pruebas de hipótesis",
    "section": "Comparaciones con lineup 2",
    "text": "Comparaciones con lineup 2\nRepitimos el ejemplo para otra muestra (en este ejemplo el proceso generador de datos es diferente para el grupo b):\n\n\n\n\n\nHacemos primero la prueba del lineup:\n\nset.seed(121)\nreps <- lineup(null_permute(\"grupo\"), muestra_tab, n = 20)\n\ndecrypt(\"pPrt Zh4h Bk VyJB4Byk uG\")\n\ngrafica_cuantiles(reps |>  mutate(grupo_escondido = factor(digest::digest2int(grupo) %% 177)), \n                             grupo_escondido, x) + facet_wrap(~.sample) + ylab(\"x\") +\n    coord_flip() + geom_point(aes(colour = grupo_escondido))\n\n`summarise()` has grouped output by 'grupo_escondido'. You can override using\nthe `.groups` argument.\n\n\n\n\n\nPodemos distinguir más o menos claramente que está localizada en valores más altos y tiene mayor dispersión. En este caso, como en general podemos identificar los datos, obtenemos evidencia en contra de que los tres grupos tienen distribuciones iguales."
  },
  {
    "objectID": "pruebas-hipotesis.html#prueba-de-permutaciones-para-proporciones",
    "href": "pruebas-hipotesis.html#prueba-de-permutaciones-para-proporciones",
    "title": "5  Pruebas de hipótesis",
    "section": "Prueba de permutaciones para proporciones",
    "text": "Prueba de permutaciones para proporciones\nVeremos otro ejemplo donde podemos hacer más concreta la idea de distribución nula o de referencia usando pruebas de permutaciones. Supongamos que con nuestra muestra de tomadores de té, queremos probar la siguiente hipótesis nula:\n\nLos tomadores de té en bolsas exclusivamente usan azúcar más a tasas simillares que los tomadores de té suelto (que pueden o no también tomar té en bolsita).\n\nLos datos que obtuvimos en nuestra encuesta, en conteos, son:\n\n\n\n\nte_azucar <- tea |> select(how, sugar) |> \n  mutate(how = ifelse(how == \"tea bag\", \"bolsa_exclusivo\", \"suelto o bolsa\"))\nte_azucar |> group_by(how, sugar) |> tally() |> \n  spread(how, n) |> \n  formatear_tabla()\n\n\n\n \n  \n    sugar \n    bolsa_exclusivo \n    suelto o bolsa \n  \n \n\n  \n    No.sugar \n    81 \n    74 \n  \n  \n    sugar \n    89 \n    56 \n  \n\n\n\n\n\nY en proporciones tenemos que:\n\n\n\n\n \n  \n    how \n    prop_azucar \n    n \n  \n \n\n  \n    bolsa_exclusivo \n    0.52 \n    170 \n  \n  \n    suelto o bolsa \n    0.43 \n    130 \n  \n\n\n\n\n\nPero distintas muestras podrían haber dado distintos resultados. Nos preguntamos que tan fuerte es la evidencia en contra de que en realidad los dos grupos de personas usan azúcar en proporciones similares, y la diferencia que vemos se puede atribuir a variación muestral.\nEn este ejemplo, podemos usar una estádistica de prueba numérica, por ejemplo, la diferencia entre las dos proporciones:\n\\[p_1 - p_2\\].\n(tomadores de en bolsa solamente vs. suelto y bolsa). El proceso sería entonces:\n\nLa hipótesis nula es que los dos grupos tienen distribuciones iguales, que este caso quiere decir que en la población, tomadores de té solo en bolsa usan azúcar a las mismas tasas que tomadores de suelto o bolsas.\nBajo nuestra hipótesis nula (proporciones iguales), producimos una cantidad grande (por ejemplo 10 mil o más) de muestras permutando las etiquetas de los grupos.\nEvaluamos nuestra estadística de prueba en cada una de las muestras permutadas.\nEl conjunto de valores obtenidos nos da nuestra distribución de referencia (ya no estamos limitados a 20 replicaciones como en las pruebas gráficas).\nY la pregunta clave es: ¿el valor de la estadística en nuestra muestra es extrema en comparación a la distribución de referencia?\n\n\n# ESta función calcula la diferencia entre grupos de interés\ncalc_diferencia <- function(datos){\n  datos |>\n    mutate(usa_azucar = as.numeric(sugar == \"sugar\")) |> \n    group_by(how) |> \n    summarise(prop_azucar = mean(usa_azucar)) |> \n    spread(how, prop_azucar) |> \n    mutate(diferencia_prop = bolsa_exclusivo - `suelto o bolsa`) |> pull(diferencia_prop)\n}\n# esta función hace permutaciones y calcula la diferencia para cada una\npermutaciones_est <- function(datos, variable, calc_diferencia, n = 1000){\n  # calcular estadística para cada grupo\n  permutar <- function(variable){\n    sample(variable, length(variable))\n  }\n  tbl_perms <- tibble(.sample = seq(1, n-1, 1)) |>\n    mutate(diferencia = map_dbl(.sample, \n              ~ datos |> mutate({{variable}}:= permutar({{variable}})) |> calc_diferencia()))\n  bind_rows(tbl_perms, tibble(.sample = n, diferencia = calc_diferencia(datos)))\n}\n\nLa diferencia observada es:\n\ndif_obs <- calc_diferencia(te_azucar)\ndif_obs |> round(3)\n\n[1] 0.093\n\n\nAhora construimos nuestra distribución nula o de referencia:\n\nvalores_ref <- permutaciones_est(te_azucar, how, calc_diferencia, n = 10000)\n\nY graficamos nuestros resultados (con un histograma y una gráfica de cuantiles, por ejemplo). la estadística evaluada un cada una de nuestras muestras permutadas:\n\ng_1 <- ggplot(valores_ref, aes(sample = diferencia)) + geom_qq(distribution = stats::qunif)  +\n    xlab(\"f\") + ylab(\"diferencia\") + labs(subtitle = \"Distribución nula o de referencia\")\ng_2 <- ggplot(valores_ref, aes(x = diferencia)) + geom_histogram(binwidth = 0.04) + \n    coord_flip() + xlab(\"\") + labs(subtitle = \" \")\ngridExtra::grid.arrange(g_1, g_2, ncol = 2) \n\n\n\n\nEste es el rango de fluctuación usual para nuestra estadística *bajo la hipótesis de que los dos grupos de tomadores de té consumen té a la misma tasa.\nEl valor que obtuvimos en nuestros datos es 0.0927602, que no es un valor extremo en la distribución de referencia que vimos arriba: esta muestra no aporta mucha evidencia en contra de que los grupos tienen distribuciones similares.\nPodemos graficar otra vez marcando el valor de referencia:\n\n# Función de distribución acumulada (inverso de función de cuantiles)\ndist_perm <- ecdf(valores_ref$diferencia)\n# Calculamos el percentil del valor observado\npercentil_obs <- dist_perm(dif_obs)\n\n\ng_1 <- ggplot(valores_ref, aes(sample = diferencia)) + geom_qq(distribution = stats::qunif)  +\n    xlab(\"f\") + ylab(\"diferencia\") + labs(subtitle = \"Distribución nula o de referencia\") +\n    geom_hline(yintercept = dif_obs, colour = \"red\") +\n    annotate(\"text\", x = 0.3, y = dif_obs - 0.05, label = \"diferencia observada\", colour = \"red\")\ng_2 <- ggplot(valores_ref, aes(x = diferencia)) + geom_histogram(binwidth = 0.04) + \n    coord_flip() + xlab(\"\") + labs(subtitle = \" \") +\n    geom_vline(xintercept = dif_obs, colour = \"red\") +\n    annotate(\"text\", x = dif_obs, y = 2000, label = percentil_obs,vjust = -0.2, colour = \"red\")\ngridExtra::grid.arrange(g_1, g_2, ncol = 2) \n\n\n\n\nY vemos que es un valor algo (pero no muy) extremo en la distribución de referencia que vimos arriba: esta muestra no aporta una gran cantidad de evidencia en contra de que los grupos tienen distribuciones similares, que en este caso significa que los dos grupos usan azúcar a tasas similares.\n\nValor p\nNótese que calculamos una cantidad adicional, que es el percentil donde nuestra observación cae en la distribución generada por las permutación. Esta cantidad puede usarse para calcular un valor p. Podemos calcular, por ejemplo:\n\nValor p de dos colas: Si la hipótesis nula es cierta, ¿cuál es la probabilidad de observar una diferencia tan extrema o más extrema de lo que observamos?\n\nConsiderando en este caso interpretamos extrema como que cae lejos de donde a mayoría de la distribución se concentra, podemos calcular el valor p como sigue. A partir de el valor observado, consideramos cuál dato es menor: la probabilidad bajo lo hipótesis nula de observar una diferencia mayor de a que observamos, o la probabilidad de observar una diferencia menor a la que observamos. Tomamos el mínimo y multiplicamos por dos (Hesterberg (2015)):\n\n2 * min(dist_perm(dif_obs), (1 - dist_perm(dif_obs)))\n\n[1] 0.1026\n\n\nEste valor p se considera como evidencia “moderada” en contra de la hipótesis nula. Valores p más chicos (observaciones más extremas en comparación con la referencia) aportan más evidencia en contra de la hipótesis de que los grupos de tomadores de té , y valores más grandes aportan menos evidencia."
  },
  {
    "objectID": "pruebas-hipotesis.html#tomadores-de-té-2",
    "href": "pruebas-hipotesis.html#tomadores-de-té-2",
    "title": "5  Pruebas de hipótesis",
    "section": "Tomadores de té 2",
    "text": "Tomadores de té 2\nAhora hacemos una prueba de permutaciones otro par de proporciones con el mismo método. La hipótesis nula ahora es:\n\nLos tomadores de té Earl Gray usan azúcar a una tasa similar a los tomadores de té negro\n\nLos datos que obtuvimos en nuestra encuesta, en conteos, son: ::: {.cell} ::: {.cell-output-display}\n\n\n \n  \n    sugar \n    black \n    Earl Grey \n  \n \n\n  \n    No.sugar \n    51 \n    84 \n  \n  \n    sugar \n    23 \n    109 \n  \n\n\n\n::: :::\nY en porcentajes tenemos que:\n\nprop_azucar <- te_azucar |> group_by(Tea, sugar) |> tally() |> \n  group_by(Tea) |> mutate(prop = 100 * n / sum(n), n = sum(n)) |> \n  filter(sugar == \"sugar\") |> select(Tea, prop_azucar = prop, n) |> \n  mutate('% usa azúcar' = round(prop_azucar)) |> select(-prop_azucar)\nprop_azucar |> formatear_tabla()\n\n\n\n \n  \n    Tea \n    n \n    % usa azúcar \n  \n \n\n  \n    black \n    74 \n    31 \n  \n  \n    Earl Grey \n    193 \n    56 \n  \n\n\n\n\n\nPero distintas muestras podrían haber dado distintos resultados. Nos preguntamos que tan fuerte es la evidencia en contra de que en realidad los dos grupos de personas usan azúcar en proporciones similares, y la diferencia que vemos se puede atribuir a variación muestral.\nEscribimos la función que calcula diferencias para cada muestra:\n\ncalc_diferencia_2 <- function(datos){\n  datos |>\n    mutate(usa_azucar = as.numeric(sugar == \"sugar\")) |> \n    group_by(Tea) |> \n    summarise(prop_azucar = mean(usa_azucar)) |> \n    spread(Tea, prop_azucar) |> \n    mutate(diferencia_prop = `Earl Grey` - black) |> pull(diferencia_prop)\n}\n\nLa diferencia observada es:\n\n\n[1] 0.254\n\n\nAhora construimos nuestra distribución nula o de referencia:\n\nset.seed(2)\nvalores_ref <- permutaciones_est(te_azucar, Tea, calc_diferencia_2, n = 10000)\n\nY podemos graficar la distribución de referencia otra vez marcando el valor observado\n\n\n\n\n\n\n\n\nEn este caso, la evidencia es muy fuerte en contra de la hipótesis nula, pues el resultado que obtuvimos es muy extremo en relación a la distribución de referencia. El valor p es cercano a 0."
  },
  {
    "objectID": "pruebas-hipotesis.html#ejemplo-tiempos-de-fusión",
    "href": "pruebas-hipotesis.html#ejemplo-tiempos-de-fusión",
    "title": "5  Pruebas de hipótesis",
    "section": "Ejemplo: tiempos de fusión",
    "text": "Ejemplo: tiempos de fusión\nConsideremos el ejemplo de fusión de estereogramas que vimos anteriormente. Una pregunta que podríamos hacer es: considerando que hay mucha variación en el tiempo de fusión dentro de cada tratamiento, necesitamos calificar la evidencia de nuestra conclusión (el tiempo de fusión se reduce con información verbal).\nPodemos usar una prueba de permutaciones, esta vez justificándola por el hecho de que los tratamientos se asignan al azar: si los tratamientos son indistinguibles, entonces las etiquetas de los grupos son solo etiquetas, y permutarlas daría muestras igualmente verosímiles.\nEn este caso, compararemos gráficas de cuantiles de los datos con los producidos por permutaciones:\n\n\n\n── Column specification ────────────────────────────────────────────────────────\ncols(\n  n = col_double(),\n  time = col_double(),\n  nv.vv = col_character()\n)\n\n\ndecrypt(\"pPrt Zh4h Bk VyJB4Byk uu\")\n\n\n\n\n\nEjercicio: ¿Podemos identificar los datos? En general, muy frecuentemente las personas identifican los datos correctamente, lo que muestra evidencia considerable de que la instrucción verbal altera los tiempos de respuesta de los partipantes, y en este caso ayuda a reducir el tiempo de fusión de los estereogramas."
  },
  {
    "objectID": "pruebas-hipotesis.html#ejemplo-tiempos-de-fusión-2",
    "href": "pruebas-hipotesis.html#ejemplo-tiempos-de-fusión-2",
    "title": "5  Pruebas de hipótesis",
    "section": "Ejemplo: tiempos de fusión 2",
    "text": "Ejemplo: tiempos de fusión 2\nPodemos usar las pruebas de permutaciones para distintos de tipos de estadísticas: medianas, medias, comparar dispersión usando rangos intercuartiles o varianzas, etc.\nRegresamos a los tiempos de fusión. Podemos hacer una prueba de permutaciones para la diferencia de las medias o medianas, por ejemplo. En este ejemplo usaremos una medida de centralidad un poco diferente, como ilustración: el promedio de los cuartiles superior e inferior de las dos distribuciones. Usaremos el cociente de estas dos cantidades para medir su diferencia\n\nstat_fusion <- function(x){\n    (quantile(x, 0.75) + quantile(x, 0.25))/2\n}\ncalc_fusion <- function(stat_fusion){\n  fun <- function(datos){\n    datos |> \n      group_by(nv.vv) |> \n      summarise(est = stat_fusion(time)) |> \n      spread(nv.vv, est) |> mutate(dif = VV / NV ) |> pull(dif)\n  }\n  fun\n}\n\n\ncalc_cociente <- calc_fusion(stat_fusion)\ndif_obs <- calc_cociente(fusion)\n# permutar\nvalores_ref <- permutaciones_est(fusion, nv.vv, calc_cociente, n = 10000)\ndist_perm_nv <- ecdf(valores_ref$diferencia) \ncuantil_obs <- dist_perm_nv(dif_obs)\n\n\n\n\n\n\nY el valor p de dos colas es\n\ndist_perm_nv <- ecdf(valores_ref$diferencia)\n2 * min(dist_perm_nv(dif_obs), 1- dist_perm_nv(dif_obs))\n\n[1] 0.0354\n\n\nLo que muestra evidencia considerable, aunque no muy fuerte, de que la instrucción verbal ayuda a reducir el tiempo de fusión de los estereogramas: la caja del diagrama de caja y brazos para el grupo VV está encogida por un factor menor a 1."
  },
  {
    "objectID": "pruebas-hipotesis.html#ojo-otros-tipos-de-hipótesis-nulas",
    "href": "pruebas-hipotesis.html#ojo-otros-tipos-de-hipótesis-nulas",
    "title": "5  Pruebas de hipótesis",
    "section": "Ojo: otros tipos de hipótesis nulas",
    "text": "Ojo: otros tipos de hipótesis nulas\nLa pruebas de permutaciones son más útiles cuando nuestra hipótesis nula se refiere que la distribución de los grupos son muy similares, o la independencia entre observaciones y grupo. Esto también aplica cuando queremos probar por ejemplo, que una variable numérica Y es independiente de X.\n\nHay algunas hipótesis que no se pueden probar con este método, como por ejemplo, las que se refieren a una sola muestra: ¿los datos son consistentes con que su media es igual a 5?\nAdicionalmente, en algunas ocasiones queremos probar aspectos más específicos de las diferencias: como ¿son iguales las medias o medianas de dos grupos de datos? ¿Tienen dispersión similar?\n\nLas pruebas de permutaciones no están tan perfectamente adaptadas a este problema, pues prueban todos los aspectos de las distribuciones que se comparan, aún cuando escogamos una estadística particular que pretende medir, por ejemplo, diferencia de medias. Eso quiere decir que podemos rechazar igualdad de medias, por ejemplo, cuando en realidad otra característica de las distribuciones es la que difiere mucho en las poblaciones\nEn algunas referencias (ver (chitim?), Efron y Tibshirani (1993)) se argumenta que de todas formas las pruebas de permutaciones son relativamente robustas a esta desadaptación. Un caso excepcional, por ejemplo, es cuando las poblaciones que comparamos resultan tener dispersión extremadamente distinta, y adicionalmente los tamaños de muestra de los grupos son muy desiguales (otra vez, ver ejemplos en (chitim?))."
  },
  {
    "objectID": "pruebas-hipotesis.html#separación-de-grupos",
    "href": "pruebas-hipotesis.html#separación-de-grupos",
    "title": "5  Pruebas de hipótesis",
    "section": "Separación de grupos",
    "text": "Separación de grupos\nEste ejemplo tomado de Chowdhury et al. (2015) (tanto la idea como el código). La pregunta que se aborda en ese estudio es:\n\nExisten métodos de clasificación (supervisados o no supervisados) para formar grupos en términos de variables que describen a los individuos\nEstos métodos (análisis discriminante, o k-means, por ejemplo), pretenden formar grupos compactos, bien separados entre ellos. Cuando aplicamos el método, obtenemos clasificadores basados en las variables de entrada.\nLa pregunta es: ¿los grupos resultantes son producto de patrones que se generalizan a la población, o capitalizaron en variación aleatoria para formarse?\nEspecialmente cuando tenemos muchas mediciones de los individuos, y una muestra relativamente chica, Es relativamente fácil encontrar combinaciones de variables que separan los grupos, aunque estas combinaciones y diferencias están basadas en ruido y no generalizan a la población.\n\nComo muestran en Chowdhury et al. (2015), el lineup es útil para juzgar si tenemos evidencia en contra de que los grupos en realidad son iguales, y usamos variación muestral para separarlos.\n\nAvispas (opcional)\nEn el siguiente ejemplo, tenemos 4 grupos de avispas (50 individuos en total), y para cada individuo se miden expresiones de 42 genes distintos. La pregunta es: ¿Podemos separar a los grupos de avispas dependiendo de sus mediciones?\nEn este se usó análisis discriminante para buscar proyecciones de los datos en dimensión baja de forma que los grupos sean lo más compactos y separados posibles.\nPara probar qué tan bien funciona este método, podemos hacer una prueba de permutación, aplicamos LDA y observamos los resultados.\n\n\n\n\n\nY vemos que incluso permutando los grupos, es generalmente posible separarlos en grupos bien definidos: la búsqueda es suficientemente agresiva para encontrar combinaciones lineales que los separan. Que no podamos distinguir los datos verdaderos de las replicaciones nulas indica que este método difícilmente puede servir para separar los grupos claramente.\nOtro enfoque sería separar los datos en una muestra de entrenamiento y una de prueba (que discutiremos en la última sesión). Aplicamos el procedimiento a la muestra de entrenamiento y luego vemos qué pasa con los datos de prueba:\n\nset.seed(8)\nwasps_1 <- wasps |> mutate(u = runif(nrow(wasps), 0, 1))\nwasps_entrena <- wasps_1 |> filter(u <= 0.8)\nwasps_prueba <- wasps_1 |> filter(u > 0.8)                            \n                            \nwasp.lda <- MASS::lda(Group ~ ., data=wasps_entrena[,-1])\nwasp_ld_entrena <- predict(wasp.lda,  dimen=2)$x |> \n    as_tibble(.name_repair = \"universal\") |>\n     mutate(tipo = \"entrenamiento\") |> \n    mutate(grupo = wasps_entrena$Group)\nwasp_ld_prueba <- predict(wasp.lda, newdata = wasps_prueba, dimen=2)$x  |> \n    as_tibble(.name_repair = \"universal\") |>\n    mutate(tipo = \"prueba\")|> \n    mutate(grupo = wasps_prueba$Group)\nwasp_lda <- bind_rows(wasp_ld_entrena, wasp_ld_prueba)\nggplot(wasp_lda, aes(x = LD1, y = LD2, colour = grupo)) + geom_point(size = 3) +\n    facet_wrap(~tipo) + scale_color_colorblind()\n\n\n\n\nAunque esta separación de datos es menos efectiva en este ejemplo por la muestra chica, podemos ver que la separación lograda en los datos de entrenamiento probablemente se debe a variación muestral."
  },
  {
    "objectID": "pruebas-hipotesis.html#la-crisis-de-replicabilidad",
    "href": "pruebas-hipotesis.html#la-crisis-de-replicabilidad",
    "title": "5  Pruebas de hipótesis",
    "section": "La “crisis de replicabilidad”",
    "text": "La “crisis de replicabilidad”\nRecientemente (Ioannidis (2005)) se ha reconocido en campos como la sicología la crisis de replicabilidad. Varios estudios que recibieron mucha publicidad inicialmente no han podido ser replicados posteriormente por otros investigadores. Por ejemplo:\n\nHacer poses poderosas produce cambios fisiológicos que mejoran nuestro desempeño en ciertas tareas\nMostrar palabras relacionadas con “viejo” hacen que las personas caminen más lento (efectos de priming)\n\nEn todos estos casos, el argumento de la evidencia de estos efectos fue respaldada por una prueba de hipótesis nula con un valor p menor a 0.05. La razón es que ese es el estándar de publicación seguido por varias áreas y revistas. La tasa de no replicabilidad parece ser mucho más alta (al menos la mitad o más según algunas fuentes, como la señalada arriba) que lo sugeriría la tasa de falsos positivos (menos de 5%)\nEste problema de replicabilidad parece ser más frecuente cuando:\n\nSe trata de estudios de potencia baja: mediciones ruidosas y tamaños de muestra chicos.\nEl plan de análisis no está claramente definido desde un principio (lo cual es difícil cuando se están investigando “fenómenos no estudiados antes”)\n\n¿A qué se atribuye esta crisis de replicabilidad?"
  },
  {
    "objectID": "pruebas-hipotesis.html#el-jardín-de-los-senderos-que-se-bifurcan",
    "href": "pruebas-hipotesis.html#el-jardín-de-los-senderos-que-se-bifurcan",
    "title": "5  Pruebas de hipótesis",
    "section": "El jardín de los senderos que se bifurcan",
    "text": "El jardín de los senderos que se bifurcan\nAunque haya algunos ejemplos de manipulaciones conscientes –e incluso, en menos casos, malintencionadas– para obtener resultados publicables o significativos (p-hacking), como vimos en ejemplos anteriores, hay varias decisiones, todas razonables, que podemos tomar cuando estamos buscando las comparaciones correctas. Algunas pueden ser:\n\nTransformar los datos (tomar o no logaritmos, u otra transformación)\nEditar datos atípicos (razonable si los equipos pueden fallar, o hay errores de captura, por ejemplo)\nDistintas maneras de interpretar los criterios de inclusión de un estudio (por ejemplo, algunos participantes mostraron tener gripa, o revelaron que durmieron muy poco la noche anterior, etc. ¿los dejamos o los quitamos?)\n\nDado un conjunto de datos, las justificaciones de las decisiones que se toman en cada paso son razonables, pero con datos distintos las decisiones podrían ser diferentes. Este es el jardín de los senderos que se bifurcan Gelman, que invalida en parte el uso valores p como criterio de evidencia contra la hipótesis nula.\nEsto es exacerbado por:\n\nTamaños de muestra chicos y efectos “inestables” que se quieren medir (por ejemplo en sicología)\nEl hecho de que el criterio de publicación es obtener un valor p < 0.05, y la presión fuerte sobre los investigadores para producir resultados publicables (p < 0.05)\nEl que estudios o resultados similares que no obtuvieron valores \\(p\\) por debajo del umbral no son publicados o reportados.\n\nVer por ejemplo el comunicado de la ASA.\nOjo: esas presiones de publicación no sólo ocurre para investigadores en sicología. Cuando trabajamos en problemas de análisis de datos en problemas que son de importancia, es común que existan intereses de algunas partes o personas involucradas por algunos resultados u otros (por ejemplo, nuestros clientes de consultoría o clientes internos). Eso puede dañar nuestro trabajo como analistas, y el avance de nuestro equipo. Aunque esas presiones son inevitables, se vuelven manejables cuando hay una relación de confianza entre las partes involucradas."
  },
  {
    "objectID": "pruebas-hipotesis.html#ejemplo-decisiones-de-análisis-y-valores-p",
    "href": "pruebas-hipotesis.html#ejemplo-decisiones-de-análisis-y-valores-p",
    "title": "5  Pruebas de hipótesis",
    "section": "Ejemplo: decisiones de análisis y valores p",
    "text": "Ejemplo: decisiones de análisis y valores p\nEn el ejemplo de datos de fusión, decidimos probar, por ejemplo, el promedio de los cuartiles inferior y superior, lo cual no es una decisión típica pero usamos como ilustración. Ahora intentamos usar distintas mediciones de la diferencia entre los grupos, usando distintas medidas resumen y transformaciones (por ejemplo, con o sin logaritmo). Aquí hay unas 12 combinaciones distintas para hacer el análisis (multiplicadas por criterios de “aceptación de datos en la muestra”, que simulamos tomando una submuestra al azar):\n\ncalc_fusion <- function(stat_fusion, trans, comparacion){\n  fun <- function(datos){\n    datos |> \n      group_by(nv.vv) |> \n      summarise(est = stat_fusion({{ trans }}(time))) |> \n      spread(nv.vv, est) |> mutate(dif = {{ comparacion }}) |> pull(dif)\n  }\n  fun\n}\nvalor_p <- function(datos, variable, calc_diferencia, n = 1000){\n  # calcular estadística para cada grupo\n  permutar <- function(variable){\n    sample(variable, length(variable))\n  }\n  tbl_perms <- tibble(.sample = seq(1, n-1, 1)) |>\n    mutate(diferencia = map_dbl(.sample, \n              ~ datos |> mutate({{variable}} := permutar({{variable}})) |> calc_diferencia()))\n  perms <- bind_rows(tbl_perms, tibble(.sample = n, diferencia = calc_diferencia(datos)))\n  perms_ecdf <- ecdf(perms$diferencia)\n  dif <- calc_diferencia(datos)\n  2 * min(perms_ecdf(dif), 1- perms_ecdf(dif))\n}\n\n\nset.seed(7272)\nmedia_cuartiles <- function(x){\n    (quantile(x, 0.75) + quantile(x, 0.25))/2\n}\n# nota: usar n=10000 o más, esto solo es para demostración:\ncalc_dif <- calc_fusion(mean, identity, VV - NV)\nvalor_p(fusion |> sample_frac(0.95), nv.vv, calc_dif, n = 1000)\n\n[1] 0.072\n\ncalc_dif <- calc_fusion(mean, log, VV - NV)\nvalor_p(fusion |> sample_frac(0.95), nv.vv, calc_dif, n = 1000)\n\n[1] 0.024\n\ncalc_dif <- calc_fusion(median, identity, VV / NV)\nvalor_p(fusion |> sample_frac(0.95), nv.vv, calc_dif, n = 1000)\n\n[1] 0.016\n\ncalc_dif <- calc_fusion(media_cuartiles, identity, VV / NV)\nvalor_p(fusion |> sample_frac(0.95), nv.vv, calc_dif, n = 1000)\n\n[1] 0.026\n\n\nSi existen grados de libertad - muchas veces necesarios para hacer un análisis exitoso-, entonces los valores p pueden tener poco significado."
  },
  {
    "objectID": "pruebas-hipotesis.html#alternativas-o-soluciones",
    "href": "pruebas-hipotesis.html#alternativas-o-soluciones",
    "title": "5  Pruebas de hipótesis",
    "section": "Alternativas o soluciones",
    "text": "Alternativas o soluciones\nEl primer punto importante es reconocer que la mayor parte de nuestro trabajo es exploratorio (recordemos el proceso complicado del análisis de datos de refinamiento de preguntas). En este tipo de trabajo, reportar valores p puede tener poco sentido, y mucho menos tiene sentido aceptar algo “verdadero” cuando pasa un umbral de significancia dado.\nNuestro interés principal al hacer análisis es expresar correctamente y de manera útil la incertidumbre asociada a las conclusiones o patrones que mostramos (asociada a variación muestral, por ejemplo) para que el proceso de toma de decisiones sea informado. Un resumen de un número (valor p, o el que sea) no puede ser tomado como criterio para tomar una decisión que generalmente es compleja. En la siguiente sección veremos cómo podemos mostrar parte de esa incertidumbre de manera más útil.\nPor otra parte, los estudios confirmatorios (donde se reportan valores p) también tienen un lugar. En áreas como la sicología, existen ahora movimientos fuertes en favor de la repetición de estudios prometedores pero donde hay sospecha de grados de libertad del investigador. Este movimiento sugiere dar valor a los estudios exploratorios que no reportan valor p, y posteriormente, si el estudio es de interés, puede intentarse una replicación confirmatoria, con potencia más alta y con planes de análisis predefinidos.\n\n\n\n\nChowdhury, Niladri Roy, Dianne Cook, Heike Hofmann, Mahbubul Majumder, Eun-Kyung Lee, y Amy L Toth. 2015. «Using visual statistical inference to better understand random class separations in high dimension, low sample size data». Computational Statistics 30 (2): 293-316.\n\n\nEfron, B., y R. Tibshirani. 1993. «An Introduction to the Bootstrap». Miscellaneous. Macmillan Publishers Limited. All rights reserved.\n\n\nHesterberg, Tim C. 2015. «What teachers should know about the bootstrap: Resampling in the undergraduate statistics curriculum». The American Statistician 69 (4): 371-86.\n\n\nIoannidis, John PA. 2005. «Why most published research findings are false». PLoS medicine 2 (8): e124.\n\n\nWickham, Hadley, Dianne Cook, Heike Hofmann, y Andreas Buja. 2010. «Graphical inference for infovis». IEEE Transactions on Visualization and Computer Graphics 16 (6): 973-79.\n\n\nWickham, H, NR Chowdhury, y D Cook. 2012. «nullabor: Tools for graphical inference». R package version 0.2 1: 213."
  }
]